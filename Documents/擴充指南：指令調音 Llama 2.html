<!DOCTYPE html> <html lang=en class="scroll-smooth dark" style=color-scheme:dark><!--
 Page saved with SingleFile 
 url: https://www.philschmid.de/instruction-tune-llama-2 
 saved date: Mon Jan 08 2024 08:25:27 GMT+0800 (Taipei Standard Time)
--><meta charset=utf-8><meta content="width=device-width, initial-scale=1" name=viewport><title>擴充指南：指令調音 Llama 2 --- Extended Guide: Instruction-tune Llama 2</title><meta name=robots content="follow, index"><meta name=description content="This blog post is an extended guide on instruction-tuning Llama 2 from Meta AI"><meta property=og:url content=https://www.philschmid.de/instruction-tune-llama-2><meta property=og:type content=article><meta property=og:site_name content="philschmid blog"><meta property=og:description content="This blog post is an extended guide on instruction-tuning Llama 2 from Meta AI"><meta property=og:title content="Extended Guide: Instruction-tune Llama 2"><meta property=og:image content=https://www.philschmid.de/static/blog/instruction-tune-llama-2/thumbnail.jpg><meta name=twitter:card content=summary_large_image><meta name=twitter:site content=https://twitter.com/_philschmid><meta name=twitter:title content="Extended Guide: Instruction-tune Llama 2"><meta name=twitter:description content="This blog post is an extended guide on instruction-tuning Llama 2 from Meta AI"><meta name=twitter:image content=https://www.philschmid.de/static/blog/instruction-tune-llama-2/thumbnail.jpg><link rel=canonical href=https://www.philschmid.de/instruction-tune-llama-2><meta property=article:published_time content=2023-07-26T00:00:00.000Z><meta property=article:modified_time content=2023-07-26T00:00:00.000Z><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.philschmid.de/instruction-tune-llama-2"},"headline":"Extended Guide: Instruction-tune Llama 2","image":[{"@type":"ImageObject","url":"https://www.philschmid.de/static/blog/instruction-tune-llama-2/thumbnail.jpg"}],"datePublished":"2023-07-26T00:00:00.000Z","dateModified":"2023-07-26T00:00:00.000Z","author":[{"@type":"Person","name":"Philipp Schmid"}],"publisher":{"@type":"Organization","name":"Philipp Schmid","logo":{"@type":"ImageObject","url":"https://www.philschmid.de/static/images/logo.png"}},"description":"This blog post is an extended guide on instruction-tuning Llama 2 from Meta AI"}</script><meta name=next-head-count content=21><meta name=msapplication-TileColor content=#000000><meta name=theme-color content=#000000><link rel=alternate type=application/rss+xml href=https://www.philschmid.de/feed.xml><style>*,:after,:before{box-sizing:border-box;border:0 solid #e5e5e5}:after,:before{--tw-content:""}html{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;-o-tab-size:4;tab-size:4;font-family:InterVariable,ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}h1,h2,h3{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}strong{font-weight:bolder}code,pre{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-size:1em}table{text-indent:0;border-color:inherit;border-collapse:collapse}button{font-family:inherit;font-size:100%;font-weight:inherit;line-height:inherit;color:inherit;margin:0}button{text-transform:none}[type=button]{-webkit-appearance:button;background-color:transparent;background-image:none}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}blockquote,dd,dl,h1,h2,h3,hr,p,pre{margin:0}ol,ul{list-style:none;margin:0;padding:0}button{cursor:pointer}:disabled{cursor:default}svg{display:block;vertical-align:middle}::-webkit-datetime-edit-fields-wrapper{padding:0}::-webkit-date-and-time-value{min-height:1.5em}::-webkit-datetime-edit,::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-meridiem-field,::-webkit-datetime-edit-millisecond-field,::-webkit-datetime-edit-minute-field,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-second-field,::-webkit-datetime-edit-year-field{padding-top:0;padding-bottom:0}@media (min-width:640px){}@media (min-width:768px){}@media (min-width:1024px){}@media (min-width:1280px){}@media (min-width:1536px){}.prose :where([class~=lead]):not(:where([class~=not-prose] *)){color:var(--tw-prose-lead);font-size:1.25em;line-height:1.6;margin-top:1.2em;margin-bottom:1.2em}.prose :where(a):not(:where([class~=not-prose] *)){color:#2563eb;text-decoration:underline;font-weight:500}.prose :where(a):not(:where([class~=not-prose] *)):hover{color:#60a5fa!important}.prose :where(a):not(:where([class~=not-prose] *)) code{color:#60a5fa}.prose :where(strong):not(:where([class~=not-prose] *)){color:#1e3a8a;font-weight:600}.prose :where(ol):not(:where([class~=not-prose] *)){list-style-type:decimal;padding-left:1.625em}.prose :where(ol[type=A]):not(:where([class~=not-prose] *)){list-style-type:upper-alpha}.prose :where(ol[type=a]):not(:where([class~=not-prose] *)){list-style-type:lower-alpha}.prose :where(ol[type=A s]):not(:where([class~=not-prose] *)){list-style-type:upper-alpha}.prose :where(ol[type=a s]):not(:where([class~=not-prose] *)){list-style-type:lower-alpha}.prose :where(ol[type=I]):not(:where([class~=not-prose] *)){list-style-type:upper-roman}.prose :where(ol[type=i]):not(:where([class~=not-prose] *)){list-style-type:lower-roman}.prose :where(ol[type=I s]):not(:where([class~=not-prose] *)){list-style-type:upper-roman}.prose :where(ol[type=i s]):not(:where([class~=not-prose] *)){list-style-type:lower-roman}.prose :where(ol[type="1"]):not(:where([class~=not-prose] *)){list-style-type:decimal}.prose :where(ul):not(:where([class~=not-prose] *)){list-style-type:disc;padding-left:1.625em}.prose :where(ol>li):not(:where([class~=not-prose] *))::marker{font-weight:400;color:var(--tw-prose-counters)}.prose :where(ul>li):not(:where([class~=not-prose] *))::marker{color:var(--tw-prose-bullets)}.prose :where(hr):not(:where([class~=not-prose] *)){border-color:#e5e5e5;border-top-width:1px;margin-top:3em;margin-bottom:3em}.prose :where(blockquote):not(:where([class~=not-prose] *)){font-weight:500;font-style:italic;color:#171717;border-left-width:.25rem;border-left-color:#e5e5e5;quotes:"“""”""‘""’";margin-top:1.6em;margin-bottom:1.6em;padding-left:1em}.prose :where(blockquote p:first-of-type):not(:where([class~=not-prose] *)):before{content:open-quote}.prose :where(blockquote p:last-of-type):not(:where([class~=not-prose] *)):after{content:close-quote}.prose :where(h1):not(:where([class~=not-prose] *)){color:#000;font-weight:700;font-size:2.25em;margin-top:0;margin-bottom:.8888889em;line-height:1.1111111;letter-spacing:-.025em}.prose :where(h1 strong):not(:where([class~=not-prose] *)){font-weight:900}.prose :where(h2):not(:where([class~=not-prose] *)){color:#000;font-weight:700;font-size:1.5em;margin-top:2em;margin-bottom:1em;line-height:1.3333333;letter-spacing:-.025em}.prose :where(h2 strong):not(:where([class~=not-prose] *)){font-weight:800}.prose :where(h3):not(:where([class~=not-prose] *)){color:#000;font-weight:600;font-size:1.25em;margin-top:1.6em;margin-bottom:.6em;line-height:1.6}.prose :where(h3 strong):not(:where([class~=not-prose] *)){font-weight:700}.prose :where(h4):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-weight:600;margin-top:1.5em;margin-bottom:.5em;line-height:1.5}.prose :where(h4 strong):not(:where([class~=not-prose] *)){font-weight:700}.prose :where(figure>*):not(:where([class~=not-prose] *)){margin-top:0;margin-bottom:0}.prose :where(figcaption):not(:where([class~=not-prose] *)){color:var(--tw-prose-captions);font-size:.875em;line-height:1.4285714;margin-top:.8571429em}.prose :where(code):not(:where([class~=not-prose] *)){color:#f97316;font-weight:600;font-size:.875em;background-color:#f5f5f5;padding:1px 2px;border-radius:.25rem}.prose :where(code):not(:where([class~=not-prose] *)):before{content:none}.prose :where(code):not(:where([class~=not-prose] *)):after{content:none}.prose :where(a code):not(:where([class~=not-prose] *)){color:var(--tw-prose-links)}.prose :where(pre):not(:where([class~=not-prose] *)){color:var(--tw-prose-pre-code);background-color:#161b22;overflow-x:auto;font-weight:400;font-size:.875rem;font-size:[object Object];line-height:1.7142857;margin-top:1.7142857em;margin-bottom:1.7142857em;border-radius:.375rem;padding:.8571429em 1.1428571em}.prose :where(pre code):not(:where([class~=not-prose] *)){background-color:transparent;border-width:0;border-radius:0;padding:0;font-weight:inherit;color:inherit;font-size:inherit;font-family:inherit;line-height:inherit}.prose :where(pre code):not(:where([class~=not-prose] *)):before{content:none}.prose :where(pre code):not(:where([class~=not-prose] *)):after{content:none}.prose :where(table):not(:where([class~=not-prose] *)){width:100%;table-layout:auto;text-align:left;margin-top:2em;margin-bottom:2em;font-size:.875em;line-height:1.7142857}.prose :where(thead):not(:where([class~=not-prose] *)){border-bottom-width:1px;border-bottom-color:var(--tw-prose-th-borders)}.prose :where(thead th):not(:where([class~=not-prose] *)){color:var(--tw-prose-headings);font-weight:600;vertical-align:bottom;padding-right:.5714286em;padding-bottom:.5714286em;padding-left:.5714286em}.prose :where(tbody tr):not(:where([class~=not-prose] *)){border-bottom-width:1px;border-bottom-color:var(--tw-prose-td-borders)}.prose :where(tbody tr:last-child):not(:where([class~=not-prose] *)){border-bottom-width:0}.prose :where(tbody td):not(:where([class~=not-prose] *)){vertical-align:baseline;padding:.5714286em}.prose{--tw-prose-body:#374151;--tw-prose-headings:#111827;--tw-prose-lead:#4b5563;--tw-prose-links:#111827;--tw-prose-bold:#111827;--tw-prose-counters:#6b7280;--tw-prose-bullets:#d1d5db;--tw-prose-hr:#e5e7eb;--tw-prose-quotes:#111827;--tw-prose-quote-borders:#e5e7eb;--tw-prose-captions:#6b7280;--tw-prose-code:#111827;--tw-prose-pre-code:#e5e7eb;--tw-prose-pre-bg:#1f2937;--tw-prose-th-borders:#d1d5db;--tw-prose-td-borders:#e5e7eb;--tw-prose-invert-body:#d1d5db;--tw-prose-invert-headings:#fff;--tw-prose-invert-lead:#9ca3af;--tw-prose-invert-links:#fff;--tw-prose-invert-bold:#fff;--tw-prose-invert-counters:#9ca3af;--tw-prose-invert-bullets:#4b5563;--tw-prose-invert-hr:#374151;--tw-prose-invert-quotes:#f3f4f6;--tw-prose-invert-quote-borders:#374151;--tw-prose-invert-captions:#9ca3af;--tw-prose-invert-code:#fff;--tw-prose-invert-pre-code:#d1d5db;--tw-prose-invert-pre-bg:rgba(0,0,0,.5);--tw-prose-invert-th-borders:#4b5563;--tw-prose-invert-td-borders:#374151}.prose :where(p):not(:where([class~=not-prose] *)){margin-top:1.25em;margin-bottom:1.25em}.prose :where(img):not(:where([class~=not-prose] *)){margin-top:2em;margin-bottom:2em}.prose :where(video):not(:where([class~=not-prose] *)){margin-top:2em;margin-bottom:2em}.prose :where(figure):not(:where([class~=not-prose] *)){margin-top:2em;margin-bottom:2em}.prose :where(h2 code):not(:where([class~=not-prose] *)){font-size:.875em}.prose :where(h3 code):not(:where([class~=not-prose] *)){font-size:.9em}.prose :where(li):not(:where([class~=not-prose] *)){margin-top:.5em;margin-bottom:.5em}.prose :where(ol>li):not(:where([class~=not-prose] *)){padding-left:.375em}.prose :where(ul>li):not(:where([class~=not-prose] *)){padding-left:.375em}.prose>:where(ul>li p):not(:where([class~=not-prose] *)){margin-top:.75em;margin-bottom:.75em}.prose>:where(ul>li>:first-child):not(:where([class~=not-prose] *)){margin-top:1.25em}.prose>:where(ul>li>:last-child):not(:where([class~=not-prose] *)){margin-bottom:1.25em}.prose>:where(ol>li>:first-child):not(:where([class~=not-prose] *)){margin-top:1.25em}.prose>:where(ol>li>:last-child):not(:where([class~=not-prose] *)){margin-bottom:1.25em}.prose :where(ul ul,ul ol,ol ul,ol ol):not(:where([class~=not-prose] *)){margin-top:.75em;margin-bottom:.75em}.prose :where(hr+*):not(:where([class~=not-prose] *)){margin-top:0}.prose :where(h2+*):not(:where([class~=not-prose] *)){margin-top:0}.prose :where(h3+*):not(:where([class~=not-prose] *)){margin-top:0}.prose :where(h4+*):not(:where([class~=not-prose] *)){margin-top:0}.prose :where(thead th:first-child):not(:where([class~=not-prose] *)){padding-left:0}.prose :where(thead th:last-child):not(:where([class~=not-prose] *)){padding-right:0}.prose :where(tbody td:first-child):not(:where([class~=not-prose] *)){padding-left:0}.prose :where(tbody td:last-child):not(:where([class~=not-prose] *)){padding-right:0}.prose>:where(:first-child):not(:where([class~=not-prose] *)){margin-top:0}.prose>:where(:last-child):not(:where([class~=not-prose] *)){margin-bottom:0}.prose :where(h4,h5,h6):not(:where([class~=not-prose] *)){color:#000}.prose :where(details):not(:where([class~=not-prose] *)){background-color:#f5f5f5;padding:2px 4px;border-radius:.25rem}.prose :where(ol li):not(:where([class~=not-prose] *))::marker{font-weight:600;color:#000}.prose :where(ul li):not(:where([class~=not-prose] *))::marker{background-color:#000}.sr-only{position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);white-space:nowrap;border-width:0}.fixed{position:fixed}.relative{position:relative}.right-8{right:2rem}.bottom-8{bottom:2rem}.mx-auto{margin-left:auto;margin-right:auto}.mb-2{margin-bottom:.5rem}.mb-3{margin-bottom:.75rem}.mt-16{margin-top:4rem}.mr-3{margin-right:.75rem}.mb-auto{margin-bottom:auto}.ml-1{margin-left:.25rem}.mr-1{margin-right:.25rem}.flex{display:flex}.hidden{display:none}.h-5{height:1.25rem}.h-screen{height:100vh}.h-8{height:2rem}.h-6{height:1.5rem}.w-5{width:1.25rem}.w-8{width:2rem}.w-6{width:1.5rem}.max-w-none{max-width:none}.max-w-3xl{max-width:48rem}@-webkit-keyframes spin{to{transform:rotate(1turn)}}@keyframes spin{to{transform:rotate(1turn)}}.flex-col{flex-direction:column}.flex-wrap{flex-wrap:wrap}.items-center{align-items:center}.justify-between{justify-content:space-between}.gap-3{gap:.75rem}.space-x-2>:not([hidden])~:not([hidden]){--tw-space-x-reverse:0;margin-right:calc(.5rem*var(--tw-space-x-reverse));margin-left:calc(.5rem*calc(1 - var(--tw-space-x-reverse)))}.space-x-4>:not([hidden])~:not([hidden]){--tw-space-x-reverse:0;margin-right:calc(1rem*var(--tw-space-x-reverse));margin-left:calc(1rem*calc(1 - var(--tw-space-x-reverse)))}.space-y-1>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(.25rem*calc(1 - var(--tw-space-y-reverse)));margin-bottom:calc(.25rem*var(--tw-space-y-reverse))}.divide-y>:not([hidden])~:not([hidden]){--tw-divide-y-reverse:0;border-top-width:calc(1px*calc(1 - var(--tw-divide-y-reverse)));border-bottom-width:calc(1px*var(--tw-divide-y-reverse))}.divide-gray-200>:not([hidden])~:not([hidden]){--tw-divide-opacity:1;border-color:rgb(229 229 229/var(--tw-divide-opacity))}.scroll-smooth{scroll-behavior:smooth}.rounded-full{border-radius:9999px}.rounded{border-radius:.25rem}.fill-current{fill:currentColor}.p-1{padding:.25rem}.p-2{padding:.5rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-1\.5{padding-left:.375rem;padding-right:.375rem}.pt-6{padding-top:1.5rem}.pb-8{padding-bottom:2rem}.pb-6{padding-bottom:1.5rem}.pb-10{padding-bottom:2.5rem}.font-serif{font-family:CHARTER}.text-sm{font-size:.875rem;line-height:1.25rem}.text-2xl{font-size:1.5rem;line-height:2rem}.text-3xl{font-size:1.875rem}.text-lg{font-size:1.125rem;line-height:1.75rem}.text-base{font-size:1rem}.font-medium{font-weight:500}.font-semibold{font-weight:600}.uppercase{text-transform:uppercase}.leading-9{line-height:2.25rem}.leading-5{line-height:1.25rem}.leading-6{line-height:1.5rem}.tracking-tight{letter-spacing:-.025em}.text-gray-500{--tw-text-opacity:1;color:rgb(115 115 115/var(--tw-text-opacity))}.text-primary-500{--tw-text-opacity:1;color:rgb(59 130 246/var(--tw-text-opacity))}.text-primary-600{--tw-text-opacity:1;color:rgb(37 99 235/var(--tw-text-opacity))}.antialiased{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.transition-all{transition-property:all;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}.transition{transition-property:color,background-color,border-color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-text-decoration-color,-webkit-backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:color,background-color,border-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-text-decoration-color,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1)}.transition{transition-duration:.15s}.duration-100{transition-duration:.1s}@font-face{font-family:CHARTER;src:local(""),url(data:font/woff;base64,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)format("woff")}.prose{font-size:1.2em;line-height:1.375}.hover\:bg-gray-300:hover{--tw-bg-opacity:1;background-color:rgb(212 212 212/var(--tw-bg-opacity))}.hover\:text-primary-600:hover{--tw-text-opacity:1;color:rgb(37 99 235/var(--tw-text-opacity))}.hover\:text-primary-500:hover{--tw-text-opacity:1;color:rgb(59 130 246/var(--tw-text-opacity))}.hover\:text-gray-600:hover{--tw-text-opacity:1;color:rgb(82 82 82/var(--tw-text-opacity))}.hover\:text-blue-500:hover{--tw-text-opacity:1;color:rgb(59 130 246/var(--tw-text-opacity))}.dark .dark\:prose-dark{color:#d4d4d4}.dark .dark\:prose-dark :where(a):not(:where([class~=not-prose] *)){color:#3b82f6}.dark .dark\:prose-dark :where(a):not(:where([class~=not-prose] *)):hover{color:#60a5fa!important}.dark .dark\:prose-dark :where(a):not(:where([class~=not-prose] *)) code{color:#60a5fa}.dark .dark\:prose-dark :where(h1):not(:where([class~=not-prose] *)){font-weight:700;letter-spacing:-.025em;color:#f5f5f5}.dark .dark\:prose-dark :where(h2):not(:where([class~=not-prose] *)){font-weight:700;letter-spacing:-.025em;color:#f5f5f5}.dark .dark\:prose-dark :where(h3):not(:where([class~=not-prose] *)){font-weight:600;color:#f5f5f5}.dark .dark\:prose-dark :where(h4,h5,h6):not(:where([class~=not-prose] *)){color:#f5f5f5}.dark .dark\:prose-dark :where(pre):not(:where([class~=not-prose] *)){background-color:#262626}.dark .dark\:prose-dark :where(code):not(:where([class~=not-prose] *)){background-color:#262626}.dark .dark\:prose-dark :where(details):not(:where([class~=not-prose] *)){background-color:#262626}.dark .dark\:prose-dark :where(hr):not(:where([class~=not-prose] *)){border-color:#404040}.dark .dark\:prose-dark :where(ol li):not(:where([class~=not-prose] *))::marker{font-weight:600;color:#a3a3a3}.dark .dark\:prose-dark :where(ul li):not(:where([class~=not-prose] *))::marker{background-color:#a3a3a3}.dark .dark\:prose-dark :where(strong):not(:where([class~=not-prose] *)){color:#f5f5f5}.dark .dark\:prose-dark :where(thead):not(:where([class~=not-prose] *)) th{color:#f5f5f5}.dark .dark\:prose-dark :where(tbody):not(:where([class~=not-prose] *)) tr{border-bottom-color:#404040}.dark .dark\:prose-dark :where(blockquote):not(:where([class~=not-prose] *)){color:#f5f5f5;border-left-color:#404040}.dark .dark\:divide-gray-700>:not([hidden])~:not([hidden]){--tw-divide-opacity:1;border-color:rgb(64 64 64/var(--tw-divide-opacity))}.dark .dark\:bg-gray-900{--tw-bg-opacity:1;background-color:rgb(23 23 23/var(--tw-bg-opacity))}.dark .dark\:bg-gray-700{--tw-bg-opacity:1;background-color:rgb(64 64 64/var(--tw-bg-opacity))}.dark .dark\:fill-gray-800{fill:#262626}.dark .dark\:text-gray-100{--tw-text-opacity:1;color:rgb(245 245 245/var(--tw-text-opacity))}.dark .dark\:text-white{--tw-text-opacity:1;color:rgb(255 255 255/var(--tw-text-opacity))}.dark .dark\:text-gray-200{--tw-text-opacity:1;color:rgb(229 229 229/var(--tw-text-opacity))}.dark .dark\:text-gray-300{--tw-text-opacity:1;color:rgb(212 212 212/var(--tw-text-opacity))}.dark .dark\:text-gray-400{--tw-text-opacity:1;color:rgb(163 163 163/var(--tw-text-opacity))}.dark .dark\:hover\:bg-gray-600:hover{--tw-bg-opacity:1;background-color:rgb(82 82 82/var(--tw-bg-opacity))}.dark .dark\:hover\:text-blue-400:hover,.dark .dark\:hover\:text-primary-400:hover{--tw-text-opacity:1;color:rgb(96 165 250/var(--tw-text-opacity))}@media (min-width:640px){.sm\:ml-4{margin-left:1rem}.sm\:block{display:block}.sm\:p-2{padding:.5rem}.sm\:px-6{padding-left:1.5rem;padding-right:1.5rem}.sm\:text-4xl{font-size:2.25rem}.sm\:leading-10{line-height:2.5rem}}@media (min-width:768px){.md\:block{display:block}.md\:flex{display:flex}.md\:divide-y-0>:not([hidden])~:not([hidden]){--tw-divide-y-reverse:0;border-top-width:calc(0px*calc(1 - var(--tw-divide-y-reverse)));border-bottom-width:calc(0px*var(--tw-divide-y-reverse))}.md\:py-10{padding-top:2.5rem;padding-bottom:2.5rem}.md\:text-5xl{font-size:3rem}.md\:leading-14{line-height:3.5rem}}@media (min-width:1024px){@media (min-width:640px){}@media (min-width:768px){}@media (min-width:1024px){}@media (min-width:1280px){}@media (min-width:1536px){}.lg\:col-span-3{grid-column:span 3/span 3}.lg\:grid{display:grid}.lg\:max-w-4xl{max-width:56rem}.lg\:grid-cols-4{grid-template-columns:repeat(4,minmax(0,1fr))}}@media (min-width:1280px){.xl\:col-span-2{grid-column:span 2/span 2}.xl\:col-span-7{grid-column:span 7/span 7}.xl\:col-start-3{grid-column-start:3}.xl\:row-span-2{grid-row:span 2/span 2}.xl\:max-w-6xl{max-width:72rem}.xl\:grid-cols-11{grid-template-columns:repeat(11,minmax(0,1fr))}.xl\:gap-x-6{-moz-column-gap:1.5rem;column-gap:1.5rem}.xl\:px-0{padding-left:0;padding-right:0}.xl\:pb-6{padding-bottom:1.5rem}.xl\:pb-0{padding-bottom:0}}.code-highlight{float:left;min-width:100%}.code-line{margin-left:-1rem;margin-right:-1rem;display:block;border-left-width:4px;border-color:transparent;padding-left:1rem;padding-right:1rem}.token.comment{color:#637777;font-style:italic}.token.punctuation{color:#c792ea}.token.keyword,.token.operator{color:#7fdbca}.token.boolean{color:#ff5874}.token.number{color:#f78c6c}.token.builtin,.token.function{color:#82aaff}.token.string{color:#addb67}.token.variable{color:#d6deeb}body{counter-reset:katexEqnNo mmlEqnNo}</style><style data-id=immersive-translate-input-injected-css>@-webkit-keyframes immersive-translate-loading-animation{from{-webkit-transform:rotate(0deg)}to{-webkit-transform:rotate(359deg)}}@keyframes immersive-translate-loading-animation{from{transform:rotate(0deg)}to{transform:rotate(359deg)}}@keyframes immersiveTranslateShadowRolling{0%{box-shadow:0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0)}12%{box-shadow:100px 0 var(--loading-color),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0)}25%{box-shadow:110px 0 var(--loading-color),100px 0 var(--loading-color),0px 0 rgba(255,255,255,0),0px 0 rgba(255,255,255,0)}36%{box-shadow:120px 0 var(--loading-color),110px 0 var(--loading-color),100px 0 var(--loading-color),0px 0 rgba(255,255,255,0)}50%{box-shadow:130px 0 var(--loading-color),120px 0 var(--loading-color),110px 0 var(--loading-color),100px 0 var(--loading-color)}62%{box-shadow:200px 0 rgba(255,255,255,0),130px 0 var(--loading-color),120px 0 var(--loading-color),110px 0 var(--loading-color)}75%{box-shadow:200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),130px 0 var(--loading-color),120px 0 var(--loading-color)}87%{box-shadow:200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),130px 0 var(--loading-color)}100%{box-shadow:200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0),200px 0 rgba(255,255,255,0)}}@media (prefers-color-scheme:dark){}</style><style data-id=immersive-translate-default-injected-css>:root{--immersive-translate-theme-underline-borderColor:#72ece9;--immersive-translate-theme-nativeUnderline-borderColor:#72ece9;--immersive-translate-theme-nativeDashed-borderColor:#72ece9;--immersive-translate-theme-nativeDotted-borderColor:#72ece9;--immersive-translate-theme-highlight-backgroundColor:#ffff00;--immersive-translate-theme-dashed-borderColor:#59c1bd;--immersive-translate-theme-blockquote-borderColor:#cc3355;--immersive-translate-theme-thinDashed-borderColor:#ff374f;--immersive-translate-theme-dashedBorder-borderColor:#94a3b8;--immersive-translate-theme-dashedBorder-borderRadius:0;--immersive-translate-theme-solidBorder-borderColor:#94a3b8;--immersive-translate-theme-solidBorder-borderRadius:0;--immersive-translate-theme-dotted-borderColor:#94a3b8;--immersive-translate-theme-wavy-borderColor:#72ece9;--immersive-translate-theme-dividingLine-borderColor:#94a3b8;--immersive-translate-theme-grey-textColor:#2f4f4f;--immersive-translate-theme-marker-backgroundColor:#fbda41;--immersive-translate-theme-marker-backgroundColor-rgb:251,218,65;--immersive-translate-theme-marker2-backgroundColor:#ffff00;--immersive-translate-theme-opacity-opacity:10}.immersive-translate-target-translation-block-wrapper{margin:8px 0!important;display:inline-block}@media all and (min-width:750px){}@media only screen and (prefers-color-scheme:dark){}@-webkit-keyframes immersive-translate-loading-animation{from{-webkit-transform:rotate(0deg)}to{-webkit-transform:rotate(359deg)}}@keyframes immersive-translate-loading-animation{from{transform:rotate(0deg)}to{transform:rotate(359deg)}}</style><meta name=referrer content=no-referrer><link rel=icon type=image/png sizes=32x32 href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAQAAADZc7J/AAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAAJcEhZcwAAAyYAAAMmAcvg128AAAAHdElNRQfmBhUUGi0Kk60wAAAB/0lEQVRIx52VT0gUYRjGf7tsrMJaoQgTHfrHSmBa3SLoYBEdvBbVJQgvQifPQSBBxiJ4W9TyIhiBh0CoQ0HiJUOKhPLUodAKNQSlsXZd2KfDOO7MfN8ssz7f6Zt5f8837zvvvJPCpoP0cpmzHOcwsMl3FnnLS/6QQB1MsI0sa5un5OvDzQxTscL+2qFAUxye53Nd2F/zHLHh51lPhAuxQrd5enLcs3CCeBOLDeFCfKC5ZjDcMC7EIEAK6GCJjFmUA2T4Bwxw2rj3kB/gkmcVYMJ+woAeCKEriuqNH1P0us7aNq3a0F8dE0IzIbyiTj/KpQVu288flSRNCaFTKgUMRoJxN+GJDe9URZJU1SUhVNjDN9QWjByDBZvB6z3go9JCLfq1u++PdiW/Tfx6KOe7QqhPkvRFmXDsGpSjeFZfQwarOiSU1oKkq9HDShaD+8ZreyyELmraTLZkpOBoyzAoKy+EcqbBmlHESdn0Iv7TZjx44YKqsuua3WAUbtW2Kb1XnJai9ffWDcjh+ts7qqd7Ju6Sy+DynD5/KE3XGZhnSFMNX3qG602jnX3NgzInfafCvgyGgiNtvmH8HdlgNg7LDeE/ORqtUTcrifFlumxlbmcu4cM7xCjLYK0rYir/KJy7KYdijInLWO3F+UpZTXL00sM5Tuz+3r/xiVleeW0T1n84a3x93uhLYQAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMi0wNi0yMVQyMDoyNjo0NSswMDowMKcqiUEAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjItMDYtMjFUMjA6MjY6NDUrMDA6MDDWdzH9AAAAGXRFWHRTb2Z0d2FyZQB3d3cuaW5rc2NhcGUub3Jnm+48GgAAAFd6VFh0UmF3IHByb2ZpbGUgdHlwZSBpcHRjAAB4nOPyDAhxVigoyk/LzEnlUgADIwsuYwsTIxNLkxQDEyBEgDTDZAMjs1Qgy9jUyMTMxBzEB8uASKBKLgDqFxF08kI1lQAAAABJRU5ErkJggg=="><style>.sf-hidden{display:none!important}</style><meta http-equiv=content-security-policy content="default-src 'none'; font-src 'self' data:; img-src 'self' data:; style-src 'unsafe-inline'; media-src 'self' data:; script-src 'unsafe-inline' data:; object-src 'self' data:; frame-src 'self' data:;"><style>img[src="data:,"],source[src="data:,"]{display:none!important}</style><noscript data-n-css></noscript><body class="bg-white text-black antialiased dark:bg-gray-900 dark:text-white"><div id=__next data-reactroot data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div class="mx-auto max-w-3xl px-1.5 sm:px-6 lg:max-w-4xl xl:max-w-6xl xl:px-0" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div class="flex h-screen flex-col justify-between" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><header class="flex items-center justify-between py-2 md:py-10" translate=no><div><a aria-label="philschmid blog" href=https://www.philschmid.de/><div class="flex items-center justify-between"><div class=mr-3><svg class="fill-black dark:fill-gray-800" width=50 height=50 viewBox="0 0 50 50" fill=none xmlns=http://www.w3.org/2000/svg><circle cx=25 cy=25 r=25></circle><path d="M21.9163 13.5879L34.5459 35.4629H9.2868L21.9163 13.5879Z" fill=white></path><path d="M26.7242 13.1627L42.7171 13.1627L34.7206 27.013L26.7242 13.1627Z" fill=white></path></svg></div><div class="text-2xl font-semibold sm:block">philschmid</div></div></a></div><div class="flex items-center text-base leading-5"><div class="hidden md:block"><a class="p-1 font-medium text-gray-900 duration-100 hover:text-primary-500 dark:text-gray-100 dark:hover:text-primary-400 sm:p-2" href=https://www.philschmid.de/>Blog</a><a class="p-1 font-medium text-gray-900 duration-100 hover:text-primary-500 dark:text-gray-100 dark:hover:text-primary-400 sm:p-2" href=https://www.philschmid.de/cloud-attention>Newsletter</a><a class="p-1 font-medium text-gray-900 duration-100 hover:text-primary-500 dark:text-gray-100 dark:hover:text-primary-400 sm:p-2" href=https://www.philschmid.de/tags>Tags</a><a class="p-1 font-medium text-gray-900 duration-100 hover:text-primary-500 dark:text-gray-100 dark:hover:text-primary-400 sm:p-2" href=https://www.philschmid.de/projects>Projects</a><a class="p-1 font-medium text-gray-900 duration-100 hover:text-primary-500 dark:text-gray-100 dark:hover:text-primary-400 sm:p-2" href=https://www.philschmid.de/philipp-schmid>About Me</a><a target=_blank rel="noopener noreferrer" href=mailto:schmidphilipp1995@gmail.com class="p-1 font-medium text-gray-900 duration-100 hover:text-primary-500 dark:text-gray-100 dark:hover:text-primary-400 sm:p-2">Contact</a></div><button aria-label="Toggle Dark Mode" type=button class="ml-1 mr-1 h-8 w-8 rounded p-1 sm:ml-4"><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 20 20" fill=currentColor class="text-gray-900 dark:text-gray-100"><path d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z" fill-rule=evenodd clip-rule=evenodd></path></svg></button><div class="md:hidden sf-hidden"></div></div></header><main class=mb-auto data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div class="mx-auto max-w-3xl px-1.5 sm:px-6 lg:max-w-4xl xl:max-w-6xl xl:px-0" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div class="fixed right-8 bottom-8 hidden flex-col gap-3 md:flex" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><button aria-label="Scroll To Top" type=button class="rounded-full bg-gray-200 p-2 text-gray-500 transition-all hover:bg-gray-300 dark:bg-gray-700 dark:text-gray-400 dark:hover:bg-gray-600"><svg class="h-5 w-5" viewBox="0 0 20 20" fill=currentColor><path fill-rule=evenodd d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z" clip-rule=evenodd></path></svg></button></div><article data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><header class="pt-6 xl:pb-6" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div class=space-y-1 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><h1 class="font-serif text-3xl leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Extended Guide: Instruction-tune Llama 2<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>擴充指南：指令調音 Llama 2</font></font></font></h1></div><div data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div class="flex flex-wrap" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><a class="mr-3 text-lg font-medium uppercase text-primary-600 hover:text-primary-500 dark:hover:text-primary-400" href=https://www.philschmid.de/tags/generativeai data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>#GenerativeAI</a><a class="mr-3 text-lg font-medium uppercase text-primary-600 hover:text-primary-500 dark:hover:text-primary-400" href=https://www.philschmid.de/tags/huggingface data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>#HuggingFace</a><a class="mr-3 text-lg font-medium uppercase text-primary-600 hover:text-primary-500 dark:hover:text-primary-400" href=https://www.philschmid.de/tags/llm data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>#LLM</a><a class="mr-3 text-lg font-medium uppercase text-primary-600 hover:text-primary-500 dark:hover:text-primary-400" href=https://www.philschmid.de/tags/llama data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>#Llama</a></div></div></div></header><div class="divide-y divide-gray-200 pb-8 dark:divide-gray-700 md:divide-y-0 lg:grid lg:grid-cols-4 xl:grid-cols-11 xl:gap-x-6" style="grid-template-rows:auto 1fr" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><dl class="pt-6 pb-10 xl:col-span-2" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><dl class=space-y-10 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><dt class=sr-only data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 style=display:none data-immersive-translate-paragraph=1>Published on<dd class="text-base leading-6 text-gray-500 dark:text-gray-400" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><time datetime=2023-07-26T00:00:00.000Z data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>July 26, 2023<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>2023 年 7 月 26 日</font></font></font></time><dd class="text-base leading-6 text-gray-500 dark:text-gray-400" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>13 min read</dd><a target=_blank rel="noopener noreferrer" href=https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/instruction-tune-llama-2-int4.ipynb class="pt-6 pb-6 text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>View Code<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1> 檢視程式碼</font></font></font></a></div></dl></dl><div class="divide-y divide-gray-200 dark:divide-gray-700 lg:col-span-3 xl:col-span-7 xl:col-start-3 xl:row-span-2 xl:pb-0" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><div class="prose max-w-none pt-6 pb-8 font-serif dark:prose-dark" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>This blog post is an extended guide on instruction-tuning Llama 2 from Meta AI. The idea of the blog post is to focus on creating the instruction dataset, which we can then use to fine-tune the base model of Llama 2 to follow our instructions.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>這篇部落格文章是關於 Meta AI 指令調優 Llama 2 的延伸指南。這篇部落格的想法是專注於創建指令資料集，然後我們可以使用它來微調 Llama 2 的基本模型以遵循我們的指示。</font></font></font><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>The goal is to create a model which can create instructions based on input. The idea behind this is that this can then be used for others to create instruction data from inputs. That's especially helpful if you want to personalize models for, e.g., tweeting, email writing, etc, which means that you would be able to generate an instruction dataset from your emails to then train a model to mimic your email writing.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>目標是創建一個可以根據輸入創建指令的模型。背後的想法是，其他人可以使用它從輸入創建指令資料。如果您想要個人化模型，例如發推文、電子郵件寫作等，這尤其有用，這意味著您將能夠從電子郵件生成指令資料集，然後訓練模型來模仿您的電子郵件寫作。</font></font></font><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Okay, so can we get started on this? In the blog, we are going to:<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>好的，那我們可以開始了嗎？在部落格中，我們將：</font></font></font><ol data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><a href=#1-define-the-use-case-and-create-a-prompt-template-for-instructions data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Define the use case and create a prompt template for instructions<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1> 定義用例並建立說明提示模板</font></font></font></a><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><a href=#2-create-an-instruction-dataset data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Create an instruction dataset<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1> 建立指令資料集</font></font></font></a><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><a href=#3-instruction-tune-llama-2-using-trl-and-the-sfttrainer data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Instruction-tune Llama 2 using <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>trl</code> and the <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>SFTTrainer</code><font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>使用 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>trl</code> 和 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>SFTTrainer</code> 指令調整 Llama 2</font></font></font></a><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><a href=#4-test-model-and-run-inference data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Test the Model and run Inference<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1> 測試模型並運行推理</font></font></font></a></ol><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><em data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Note: This tutorial was created and run on a g5.2xlarge AWS EC2 Instance, including an NVIDIA A10G GPU.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>注意：本教學是在 g5.2xlarge AWS EC2 執行個體（包括 NVIDIA A10G GPU）上建立和執行的。</font></font></font></em><h2 id=1-define-the-use-case-and-create-a-prompt-template-for-instructions data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1><a href=#1-define-the-use-case-and-create-a-prompt-template-for-instructions aria-hidden=true tabindex=-1 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><span class="icon icon-link" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6></span></a>1. Define the use case and create a prompt template for instructions<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>1. 定義用例並建立說明提示模板</font></font></font></h2><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Before we describe our use case, we need to better understand what even is an instruction.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>在描述我們的用例之前，我們需要更好地理解什麼是指令。</font></font></font><blockquote data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>An instruction is a piece of text or prompt that is provided to an LLM, like Llama, GPT-4, or Claude, to guide it to generate a response. Instructions allow humans to steer the conversation and constrain the language model's output to be more natural, useful, and aligned with the user's goals. Crafting clear, well-formulated instructions is key to productive conversations.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>指令是提供給 LLM（如 Llama、GPT-4 或 Claude）的一段文字或提示，以指導其產生回應。指令允許人類引導對話並限制語言模型的輸出，使其更加自然、有用並且與使用者的目標保持一致。制定清晰、完善的說明是富有成效的對話的關鍵。</font></font></font></p></blockquote><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Examples of instructions are listed below in the table.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>下表列出了指令範例。</font></font></font><table data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><thead data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><tr data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><th data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Capability<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>能力</font></font></font><th data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Example Instruction<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>範例說明</font></font></font><tbody data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><tr data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Brainstorming<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>腦力激盪</font></font></font><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Provide a diverse set of creative ideas for new flavors of ice cream.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>為新口味的冰淇淋提供多元化的創意。</font></font></font><tr data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Classification<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>分類</font></font></font><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Categorize these movies as either comedy, drama, or horror based on the plot summary.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>根據情節摘要將這些電影分類為喜劇、戲劇或恐怖。</font></font></font><tr data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Closed QA<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>封閉式品質檢查</font></font></font><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Answer the question 'What is the capital of France?' with a single word.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>回答「法國的首都是哪裡？」的問題一句話。</font></font></font><tr data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Generation<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>世代</font></font></font><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Write a poem in the style of Robert Frost about nature and the changing seasons.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>以羅伯特·弗羅斯特的風格寫一首關於自然和季節變化的詩。</font></font></font><tr data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Information Extraction<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>資訊擷取</font></font></font><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Extract the names of the main characters from this short story.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>從這個短篇小說中提取主要人物的名字。</font></font></font><tr data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Open QA<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>開放品質檢查</font></font></font><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Why do leaves change color in autumn? Explain the scientific reasons.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>為什麼樹葉在秋天會變色？解釋一下科學原因。</font></font></font><tr data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Summarization<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>總結</font></font></font><td data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Summarize this article on recent advancements in renewable energy in 2-3 sentences.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>用 2-3 句話總結本文有關再生能源的最新進展。</font></font></font></table><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>As described in the beginning, we want to fine-tune a model to be able to generate instructions based on input. (output). We want to use this as a way to create synthetic datasets to personalize LLMs and Agents.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>如一開始所描述的，我們希望微調模型，以便能夠根據輸入產生指令。 （輸出）。我們希望用它來創建綜合數據集來個性化法學碩士和代理人。</font></font></font><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Converting the idea into a basic prompt template following the <a target=_blank rel="noopener noreferrer" href=https://github.com/tatsu-lab/stanford_alpaca#data-release data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Alpaca format</a> we get.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>將這個想法轉換成我們得到的羊駝格式的基本提示模板。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token comment">### Instruction:</span>
</span><span class=code-line>Use the Input below to create an instruction<span class="token punctuation">,</span> which could have been used to generate the <span class="token builtin">input</span> using an LLM<span class="token punctuation">.</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment">### Input:</span>
</span><span class=code-line>Dear <span class="token punctuation">[</span>boss name<span class="token punctuation">]</span><span class="token punctuation">,</span>
</span><span class=code-line>
</span><span class=code-line>I'm writing to request <span class="token builtin">next</span> week<span class="token punctuation">,</span> August 1st through August 4th<span class="token punctuation">,</span>
</span><span class=code-line>off <span class="token keyword">as</span> paid time off<span class="token punctuation">.</span>
</span><span class=code-line>
</span><span class=code-line>I have some personal matters to attend to that week that require
</span><span class=code-line>me to be out of the office<span class="token punctuation">.</span> I wanted to give you <span class="token keyword">as</span> much advance
</span><span class=code-line>notice <span class="token keyword">as</span> possible so you can plan accordingly <span class="token keyword">while</span> I am away<span class="token punctuation">.</span>
</span><span class=code-line>
</span><span class=code-line>Please let me know <span class="token keyword">if</span> you need <span class="token builtin">any</span> additional information <span class="token keyword">from</span> me
</span><span class=code-line><span class="token keyword">or</span> have <span class="token builtin">any</span> concerns <span class="token keyword">with</span> me taking <span class="token builtin">next</span> week off<span class="token punctuation">.</span> I appreciate you
</span><span class=code-line>considering this request<span class="token punctuation">.</span>
</span><span class=code-line>
</span><span class=code-line>Thank you<span class="token punctuation">,</span> <span class="token punctuation">[</span>Your name<span class="token punctuation">]</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment">### Response:</span>
</span><span class=code-line>Write an email to my boss that I need <span class="token builtin">next</span> week <span class="token number">08</span><span class="token operator">/</span><span class="token number">01</span> <span class="token operator">-</span> <span class="token number">08</span><span class="token operator">/</span><span class="token number">04</span> off<span class="token punctuation">.</span>
</span></code></pre></div><h2 id=2-create-an-instruction-dataset data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1><a href=#2-create-an-instruction-dataset aria-hidden=true tabindex=-1 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><span class="icon icon-link" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6></span></a>2. Create an instruction dataset<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1> 2. 建立指令資料集</font></font></font></h2><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>After we defined our use case and prompt template, we need to create our instruction dataset. Creating a high-quality instruction dataset is key for a good-performing model. Research shows that <a target=_blank rel="noopener noreferrer" href=https://arxiv.org/abs/2305.11206 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>“Less Is More for Alignment”</a> shows that creating a high-quality, low-quantity (~1000 samples) dataset can achieve the same performance as less-quality and high-quantity datasets.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>定義用例和提示範本後，我們需要建立指令資料集。創建高品質的指令資料集是效能良好的模型的關鍵。研究表明，「對齊少即是多」表明，創建高品質、低數量（約 1000 個樣本）的數據集可以實現與低品質、高品質數據集相同的效能。</font></font></font><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>There are several ways to create an instruction dataset, including:<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>建立指令資料集的方法有多種，包括：</font></font></font><ol data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Using an existing dataset and converting it into an instruction dataset, e.g., <a target=_blank rel="noopener noreferrer" href=https://huggingface.co/datasets/SirNeural/flan_v2 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>FLAN</a><font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>使用現有資料集並將其轉換為指令資料集，例如 FLAN</font></font></font><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Use existing LLMs to create synthetically instruction datasets, e.g., <a target=_blank rel="noopener noreferrer" href=https://huggingface.co/datasets/tatsu-lab/alpaca data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Alpaca</a><font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>使用現有的法學碩士建立綜合教學資料集，例如 Alpaca</font></font></font><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Use Humans to create instructions datasets, e.g., <a target=_blank rel="noopener noreferrer" href=https://huggingface.co/datasets/databricks/databricks-dolly-15k data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Dolly</a>.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>使用人類建立指令資料集，例如 Dolly。</font></font></font></ol><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Each of the methods has its own advantages and disadvantages and depends on the budget, time, and quality requirements. For example, using an existing dataset is the easiest but might not be tailored to your specific use case, while using humans might be the most accurate but can be time-consuming and expensive. It is also possible to combine several methods to create an instruction dataset, as shown in <a target=_blank rel="noopener noreferrer" href=https://arxiv.org/abs/2306.02707 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Orca: Progressive Learning from Complex Explanation Traces of GPT-4.</a><font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>每種方法都有其自身的優點和缺點，取決於預算、時間和品質要求。例如，使用現有資料集是最簡單的，但可能無法針對您的特定用例進行定制，而使用人類可能是最準確的，但可能既耗時又昂貴。也可以結合多種方法來建立指令資料集，如 Orca：從 GPT-4 的複雜解釋軌跡進行漸進學習中所示。</font></font></font><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>To keep it simple, we are going to use <strong data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><a target=_blank rel="noopener noreferrer" href=https://huggingface.co/datasets/databricks/databricks-dolly-15k data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Dolly</a></strong> an open-source dataset of instruction-following records generated by thousands of Databricks employees in several of the behavioral categories outlined in the <strong data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><a target=_blank rel="noopener noreferrer" href=https://arxiv.org/abs/2203.02155 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>InstructGPT paper</a></strong>, including brainstorming, classification, closed QA, generation, information extraction, open QA, and summarization.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>為了簡單起見，我們將使用Dolly，這是一個由數千名Databricks 員工生成的指令追蹤記錄的開源資料集，涉及InstructGPT 論文中概述的幾個行為類別，包括腦力激盪、分類、封閉式QA、生成、資訊擷取、開放式 QA 和總結。</font></font></font><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Let's start coding, but first, let's install our dependencies.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>讓我們開始編碼，但首先，讓我們安裝依賴項。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line>!pip install <span class="token string">"transformers==4.34.0"</span> <span class="token string">"datasets==2.13.0"</span> <span class="token string">"peft==0.4.0"</span> <span class="token string">"accelerate==0.23.0"</span> <span class="token string">"bitsandbytes==0.41.1"</span> <span class="token string">"trl==0.4.7"</span> <span class="token string">"safetensors&gt;=0.3.1"</span> <span class="token operator">-</span><span class="token operator">-</span>upgrade
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>To load the <strong data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>databricks/databricks-dolly-15k</code></strong> dataset, we use the <strong data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>load_dataset()</code></strong> method from the 🤗 Datasets library.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>要載入 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>databricks/databricks-dolly-15k</code> 資料集，我們使用 🤗 資料集庫中的 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>load_dataset()</code> 方法。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
</span><span class=code-line><span class="token keyword">from</span> random <span class="token keyword">import</span> randrange
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># Load dataset from the hub</span>
</span><span class=code-line>dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"databricks/databricks-dolly-15k"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>
</span><span class=code-line>
</span><span class=code-line><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"dataset size: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</span><span class=code-line><span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span>randrange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class=code-line><span class="token comment"># dataset size: 15011</span>
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>To instruct tune our model, we need to convert our structured examples into a collection of tasks described via instructions. We define a <strong data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>formatting_function</code></strong> that takes a sample and returns a string with our format instruction.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>為了指導調整我們的模型，我們需要將結構化範例轉換為透過指令描述的任務集合。我們定義一個 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>formatting_function</code> 來取得樣本並傳回帶有格式指令的字串。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">def</span> <span class="token function">format_instruction</span><span class="token punctuation">(</span>sample<span class="token punctuation">)</span><span class="token punctuation">:</span>
</span><span class=code-line>	<span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f"""### Instruction:
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">Use the Input below to create an instruction, which could have been used to generate the input using an LLM.
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">### Input:
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string"></span><span class="token interpolation"><span class="token punctuation">{</span>sample<span class="token punctuation">[</span><span class="token string">'response'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">### Response:
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string"></span><span class="token interpolation"><span class="token punctuation">{</span>sample<span class="token punctuation">[</span><span class="token string">'instruction'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">"""</span></span>
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Let's test our formatting function on a random example.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1> 讓我們在一個隨機範例上測試我們的格式化函數。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">from</span> random <span class="token keyword">import</span> randrange
</span><span class=code-line>
</span><span class=code-line><span class="token keyword">print</span><span class="token punctuation">(</span>format_instruction<span class="token punctuation">(</span>dataset<span class="token punctuation">[</span>randrange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class=code-line><span class="token comment">### Instruction:</span>
</span><span class=code-line>Use the Input below to create an instruction<span class="token punctuation">,</span> which could have been used to generate the <span class="token builtin">input</span> using an LLM<span class="token punctuation">.</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment">### Input:</span>
</span><span class=code-line>22nd July <span class="token number">1947</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment">### Response:</span>
</span><span class=code-line>When was the Indian National Flag adopted
</span></code></pre></div><h2 id=3-instruction-tune-llama-2-using-trl-and-the-sfttrainer data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1><a href=#3-instruction-tune-llama-2-using-trl-and-the-sfttrainer aria-hidden=true tabindex=-1 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><span class="icon icon-link" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6></span></a>3. Instruction-tune Llama 2 using <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>trl</code> and the <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>SFTTrainer</code><font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>3. 使用 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>trl</code> 和 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>SFTTrainer</code> 指令調整 Llama 2</font></font></font></h2><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>We will use the recently introduced method in the paper "<a target=_blank rel="noopener noreferrer" href=https://arxiv.org/abs/2305.14314 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>QLoRA: Quantization-aware Low-Rank Adapter Tuning for Language Generation</a>" by Tim Dettmers et al. QLoRA is a new technique to reduce the memory footprint of large language models during finetuning, without sacrificing performance. The TL;DR; of how QLoRA works is:<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>我們將使用 Tim Dettmers 等人的論文「QLoRA：Quantization-aware Low-Rank Adapter Tuning for Language Generation」中最近介紹的方法。 QLoRA 是一種新技術，可在不犧牲效能的情況下減少大型語言模型在微調期間的記憶體佔用。 TL;DR; QLoRA 的工作原理是：</font></font></font><ul data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Quantize the pre-trained model to 4 bits and freeze it.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>將預訓練模型量化為 4 位元並凍結。</font></font></font><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Attach small, trainable adapter layers. (LoRA)<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>附加小型、可訓練的適配器層。 （洛拉）</font></font></font><li data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Finetune only the adapter layers while using the frozen quantized model for context.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>僅微調適配器層，同時使用凍結的量化模型作為上下文。</font></font></font></ul><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>If you want to learn more about QLoRA and how it works, I recommend you to read the <a target=_blank rel="noopener noreferrer" href=https://huggingface.co/blog/4bit-transformers-bitsandbytes data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA</a> blog post.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>如果您想了解有關 QLoRA 及其工作原理的更多信息，我建議您閱讀通過位元和位元組、4 位量化和 QLoRA 讓 LLM 更容易訪問部落格文章。</font></font></font><h3 id=flash-attention data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1><a href=#flash-attention aria-hidden=true tabindex=-1 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><span class="icon icon-link" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6></span></a>Flash Attention<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>閃光注意</font></font></font></h3><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Flash Attention is a an method that reorders the attention computation and leverages classical techniques (tiling, recomputation) to significantly speed it up and reduce memory usage from quadratic to linear in sequence length. It is based on the paper "<a target=_blank rel="noopener noreferrer" href=https://arxiv.org/abs/2205.14135 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a>". The TL;DR; accelerates training up to 3x. Learn more at <a target=_blank rel="noopener noreferrer" href=https://github.com/Dao-AILab/flash-attention/tree/main data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>FlashAttention</a>. Flash Attention is currently only available for Ampere (A10, A40, A100, ...) &amp; Hopper (H100, ...) GPUs. You can check if your GPU is supported and install it using the following command:<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>Flash Attention 是一種對注意力計算進行重新排序並利用經典技術（平鋪、重新計算）來顯著加快計算速度並減少序列長度的記憶體使用量的方法，從二次到線性。它基於論文“FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness”。 TL;DR;將訓練加速高達 3 倍。了解更多信息，請訪問 FlashAttention。 Flash Attention 目前僅適用於 Ampere（A10、A40、A100，...） 和 Hopper（H100，...） GPU。您可以使用以下命令檢查您的 GPU 是否受支援並安裝它：</font></font></font><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><em data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Note: If your machine has less than 96GB of RAM and lots of CPU cores, reduce the number of <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>MAX_JOBS</code>. On the <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>g5.2xlarge</code> we used <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>4</code>.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>注意：如果您的電腦的 RAM 小於 96GB 且 CPU 核心較多，請減少 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>MAX_JOBS</code> 的數量。在 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>g5.2xlarge</code> 上，我們使用了 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>4</code> 。</font></font></font></em><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="code-highlight language-bash"><span class=code-line>python -c <span class="token string">"import torch; assert torch.cuda.get_device_capability()[0] &gt;= 8, 'Hardware not supported for Flash Attention'"</span>
</span><span class=code-line>pip <span class="token function">install</span> ninja packaging
</span><span class=code-line><span class="token assign-left variable">MAX_JOBS</span><span class="token operator">=</span><span class="token number">4</span> pip <span class="token function">install</span> flash-attn --no-build-isolation
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><em data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Installing flash attention can take quite a bit of time (10-45 minutes).<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>安裝 Flash 注意可能需要相當長的時間（10-45 分鐘）。</font></font></font></em><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>The example supports the use of Flash Attention for all Llama checkpoints, but is not enabled by default. To use Flash Attention change the value of <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>use_flash_attentin</code> to <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>True</code><font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>此範例支援對所有 Llama 檢查點使用 Flash Attention，但預設未啟用。若要使用 Flash Attention，請將 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>use_flash_attentin</code> 的值變更為 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>True</code> </font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">import</span> torch
</span><span class=code-line><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM<span class="token punctuation">,</span> BitsAndBytesConfig
</span><span class=code-line>
</span><span class=code-line>use_flash_attention <span class="token operator">=</span> <span class="token boolean">False</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># Hugging Face model id</span>
</span><span class=code-line>model_id <span class="token operator">=</span> <span class="token string">"NousResearch/Llama-2-7b-hf"</span>  <span class="token comment"># non-gated</span>
</span><span class=code-line><span class="token comment"># model_id = "meta-llama/Llama-2-7b-hf" # gated</span>
</span><span class=code-line>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># BitsAndBytesConfig int-4 config</span>
</span><span class=code-line>bnb_config <span class="token operator">=</span> BitsAndBytesConfig<span class="token punctuation">(</span>
</span><span class=code-line>    load_in_4bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> bnb_4bit_use_double_quant<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> bnb_4bit_quant_type<span class="token operator">=</span><span class="token string">"nf4"</span><span class="token punctuation">,</span> bnb_4bit_compute_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bfloat16
</span><span class=code-line><span class="token punctuation">)</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># Load model and tokenizer</span>
</span><span class=code-line>model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
</span><span class=code-line>    model_id<span class="token punctuation">,</span>
</span><span class=code-line>    quantization_config<span class="token operator">=</span>bnb_config<span class="token punctuation">,</span>
</span><span class=code-line>    use_cache<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
</span><span class=code-line>    use_flash_attention_2<span class="token operator">=</span>use_flash_attention<span class="token punctuation">,</span>
</span><span class=code-line>    device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span>
</span><span class=code-line><span class="token punctuation">)</span>
</span><span class=code-line>model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>pretraining_tp <span class="token operator">=</span> <span class="token number">1</span>
</span><span class=code-line>
</span><span class=code-line>
</span><span class=code-line>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>
</span><span class=code-line>tokenizer<span class="token punctuation">.</span>pad_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>eos_token
</span><span class=code-line>tokenizer<span class="token punctuation">.</span>padding_side <span class="token operator">=</span> <span class="token string">"right"</span>
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>The <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>SFTTrainer</code> supports a native integration with <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>peft</code>, which makes it super easy to efficiently instruction tune LLMs. We only need to create our <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>LoRAConfig</code> and provide it to the trainer.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1> <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>SFTTrainer</code> 支援與 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>peft</code> 的本機集成，這使得高效指令調整 LLM 變得非常容易。我們只需要創建我們的 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>LoRAConfig</code> 並將其提供給培訓師。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">from</span> peft <span class="token keyword">import</span> LoraConfig<span class="token punctuation">,</span> prepare_model_for_kbit_training<span class="token punctuation">,</span> get_peft_model
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># LoRA config based on QLoRA paper</span>
</span><span class=code-line>peft_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>
</span><span class=code-line>        lora_alpha<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
</span><span class=code-line>        lora_dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
</span><span class=code-line>        r<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
</span><span class=code-line>        bias<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span>
</span><span class=code-line>        task_type<span class="token operator">=</span><span class="token string">"CAUSAL_LM"</span><span class="token punctuation">,</span>
</span><span class=code-line><span class="token punctuation">)</span>
</span><span class=code-line>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># prepare model for training</span>
</span><span class=code-line>model <span class="token operator">=</span> prepare_model_for_kbit_training<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
</span><span class=code-line>model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> peft_config<span class="token punctuation">)</span>
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Before we can start our training we need to define the hyperparameters (<code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>TrainingArguments</code>) we want to use.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>在開始訓練之前，我們需要定義要使用的超參數 ( <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>TrainingArguments</code> )。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments
</span><span class=code-line>
</span><span class=code-line>args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
</span><span class=code-line>    output_dir<span class="token operator">=</span><span class="token string">"llama-7-int4-dolly"</span><span class="token punctuation">,</span>
</span><span class=code-line>    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
</span><span class=code-line>    per_device_train_batch_size<span class="token operator">=</span><span class="token number">6</span> <span class="token keyword">if</span> use_flash_attention <span class="token keyword">else</span> <span class="token number">4</span><span class="token punctuation">,</span>
</span><span class=code-line>    gradient_accumulation_steps<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
</span><span class=code-line>    gradient_checkpointing<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
</span><span class=code-line>    optim<span class="token operator">=</span><span class="token string">"paged_adamw_32bit"</span><span class="token punctuation">,</span>
</span><span class=code-line>    logging_steps<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
</span><span class=code-line>    save_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
</span><span class=code-line>    learning_rate<span class="token operator">=</span><span class="token number">2e-4</span><span class="token punctuation">,</span>
</span><span class=code-line>    bf16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
</span><span class=code-line>    tf32<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
</span><span class=code-line>    max_grad_norm<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>
</span><span class=code-line>    warmup_ratio<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">,</span>
</span><span class=code-line>    lr_scheduler_type<span class="token operator">=</span><span class="token string">"constant"</span><span class="token punctuation">,</span>
</span><span class=code-line>    disable_tqdm<span class="token operator">=</span><span class="token boolean">True</span> <span class="token comment"># disable tqdm since with packing values are in correct</span>
</span><span class=code-line><span class="token punctuation">)</span>
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>We now have every building block we need to create our <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>SFTTrainer</code> to start then training our model.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>我們現在擁有創建 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>SFTTrainer</code> 所需的每個構建塊，然後開始訓練我們的模型。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">from</span> trl <span class="token keyword">import</span> SFTTrainer
</span><span class=code-line>
</span><span class=code-line>max_seq_length <span class="token operator">=</span> <span class="token number">2048</span> <span class="token comment"># max sequence length for model and packing of the dataset</span>
</span><span class=code-line>
</span><span class=code-line>trainer <span class="token operator">=</span> SFTTrainer<span class="token punctuation">(</span>
</span><span class=code-line>    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
</span><span class=code-line>    train_dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>
</span><span class=code-line>    peft_config<span class="token operator">=</span>peft_config<span class="token punctuation">,</span>
</span><span class=code-line>    max_seq_length<span class="token operator">=</span>max_seq_length<span class="token punctuation">,</span>
</span><span class=code-line>    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
</span><span class=code-line>    packing<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
</span><span class=code-line>    formatting_func<span class="token operator">=</span>format_instruction<span class="token punctuation">,</span>
</span><span class=code-line>    args<span class="token operator">=</span>args<span class="token punctuation">,</span>
</span><span class=code-line><span class="token punctuation">)</span>
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Start training our model by calling the <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>train()</code> method on our <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Trainer</code> instance.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>透過呼叫 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Trainer</code> 實例上的 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>train()</code> 方法開始訓練我們的模型。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token comment"># train</span>
</span><span class=code-line>trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># there will not be a progress bar since tqdm is disabled</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># save model</span>
</span><span class=code-line>trainer<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>The training without Flash Attention enabled took 03:08:00 on a <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>g5.2xlarge</code>. The instance costs <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>1,212$/h</code> which brings us to a total cost of <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>3.7$</code>. The training with Flash Attention enabled took 02:08:00 on a <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>g5.2xlarge</code>. The instance costs <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>1,212$/h</code> which brings us to a total cost of <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>2.6$</code>.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>未啟用 Flash Attention 的訓練在 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>g5.2xlarge</code> 上花費了 03:08:00 。實例成本為 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>1,212$/h</code> ，總成本為 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>3.7$</code> 。啟用 Flash Attention 的訓練在 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>g5.2xlarge</code> 上花費了 02:08:00 。此實例的成本為 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>1,212$/h</code> ，總成本為 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>2.6$</code> 。</font></font></font><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>The results using Flash Attention are mind blowing and impressive, 1.5x faster and 30% cheaper.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>使用 Flash Attention 的結果令人驚嘆且令人印象深刻，速度提高了 1.5 倍，成本降低了 30%。</font></font></font><h2 id=4-test-model-and-run-inference data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1><a href=#4-test-model-and-run-inference aria-hidden=true tabindex=-1 data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><span class="icon icon-link" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6></span></a>4. Test Model and run Inference<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>4. 測試模型並運行推理</font></font></font></h2><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>After the training is done we want to run and test our model. We will use <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>peft</code> and <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>transformers</code> to load our LoRA adapter into our model.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>訓練完成後，我們要執行並測試我們的模型。我們將使用 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>peft</code> 和 <code data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>transformers</code> 將 LoRA 適配器載入到我們的模型中。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">if</span> use_flash_attention<span class="token punctuation">:</span>
</span><span class=code-line>    <span class="token comment"># unpatch flash attention</span>
</span><span class=code-line>    <span class="token keyword">from</span> utils<span class="token punctuation">.</span>llama_patch <span class="token keyword">import</span> unplace_flash_attn_with_attn
</span><span class=code-line>    unplace_flash_attn_with_attn<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class=code-line>
</span><span class=code-line><span class="token keyword">import</span> torch
</span><span class=code-line><span class="token keyword">from</span> peft <span class="token keyword">import</span> AutoPeftModelForCausalLM
</span><span class=code-line><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer
</span><span class=code-line>
</span><span class=code-line>args<span class="token punctuation">.</span>output_dir <span class="token operator">=</span> <span class="token string">"llama-7-int4-dolly"</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># load base LLM model and tokenizer</span>
</span><span class=code-line>model <span class="token operator">=</span> AutoPeftModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
</span><span class=code-line>    args<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span>
</span><span class=code-line>    low_cpu_mem_usage<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
</span><span class=code-line>    torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">,</span>
</span><span class=code-line>    load_in_4bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
</span><span class=code-line><span class="token punctuation">)</span>
</span><span class=code-line>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>args<span class="token punctuation">.</span>output_dir<span class="token punctuation">)</span>
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Let’s load the dataset again with a random sample to try to generate an instruction.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>讓我們再次使用隨機樣本載入資料集以嘗試產生指令。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
</span><span class=code-line><span class="token keyword">from</span> random <span class="token keyword">import</span> randrange
</span><span class=code-line>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># Load dataset from the hub and get a sample</span>
</span><span class=code-line>dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"databricks/databricks-dolly-15k"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>
</span><span class=code-line>sample <span class="token operator">=</span> dataset<span class="token punctuation">[</span>randrange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</span><span class=code-line>
</span><span class=code-line>prompt <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"""### Instruction:
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">Use the Input below to create an instruction, which could have been used to generate the input using an LLM.
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">### Input:
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string"></span><span class="token interpolation"><span class="token punctuation">{</span>sample<span class="token punctuation">[</span><span class="token string">'response'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">### Response:
</span></span></span><span class=code-line><span class="token string-interpolation"><span class="token string">"""</span></span>
</span><span class=code-line>
</span><span class=code-line>input_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>input_ids<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class=code-line><span class="token comment"># with torch.inference_mode():</span>
</span><span class=code-line>outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>input_ids<span class="token operator">=</span>input_ids<span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> top_p<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>
</span><span class=code-line>
</span><span class=code-line><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Prompt:\n</span><span class="token interpolation"><span class="token punctuation">{</span>sample<span class="token punctuation">[</span><span class="token string">'response'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">\n"</span></span><span class="token punctuation">)</span>
</span><span class=code-line><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Generated instruction:\n</span><span class="token interpolation"><span class="token punctuation">{</span>tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</span><span class=code-line><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Ground truth:\n</span><span class="token interpolation"><span class="token punctuation">{</span>sample<span class="token punctuation">[</span><span class="token string">'instruction'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>result<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><font class=notranslate data-immersive-translate-translation-element-mark=1>&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>結果</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class=code-highlight><span class=code-line>Prompt:
</span><span class=code-line>Jack Dorsey, Noah Glass, Biz Stone, Evan Williams
</span><span class=code-line>
</span><span class=code-line>Generated instruction:
</span><span class=code-line>Extract the founders of Twitter from the passage. Display the results in a comma separated format.
</span><span class=code-line>
</span><span class=code-line>Ground truth:
</span><span class=code-line>List the founders of Twitter from the above passage in a comma separated format.
</span></code></pre></div><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Nice! our model works! If want to accelerate our model we can deploy it with <a target=_blank rel="noopener noreferrer" href=https://github.com/huggingface/text-generation-inference data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Text Generation Inference</a>. Therefore we would need to merge our adapter weights into the base model.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>好的！我們的模型有效！如果想要加速我們的模型，我們可以使用文字生成推理來部署它。因此，我們需要將適配器權重合併到基本模型中。</font></font></font><div class=relative data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><pre><code class="language-python code-highlight"><span class=code-line><span class="token keyword">from</span> peft <span class="token keyword">import</span> AutoPeftModelForCausalLM
</span><span class=code-line>
</span><span class=code-line>model <span class="token operator">=</span> AutoPeftModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
</span><span class=code-line>    args<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span>
</span><span class=code-line>    low_cpu_mem_usage<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
</span><span class=code-line><span class="token punctuation">)</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># Merge LoRA and base model</span>
</span><span class=code-line>merged_model <span class="token operator">=</span> model<span class="token punctuation">.</span>merge_and_unload<span class="token punctuation">(</span><span class="token punctuation">)</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># Save the merged model</span>
</span><span class=code-line>merged_model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">"merged_model"</span><span class="token punctuation">,</span>safe_serialization<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</span><span class=code-line>tokenizer<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">"merged_model"</span><span class="token punctuation">)</span>
</span><span class=code-line>
</span><span class=code-line><span class="token comment"># push merged model to the hub</span>
</span><span class=code-line><span class="token comment"># merged_model.push_to_hub("user/repo")</span>
</span><span class=code-line><span class="token comment"># tokenizer.push_to_hub("user/repo")</span>
</span></code></pre></div><hr><p data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1>Thanks for reading! If you have any questions, feel free to contact me on <a target=_blank rel="noopener noreferrer" href=https://twitter.com/_philschmid data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Twitter</a> or <a target=_blank rel="noopener noreferrer" href=https://www.linkedin.com/in/philipp-schmid-a6a2bb196/ data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>LinkedIn</a>.<font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1>謝謝閱讀！如果您有任何疑問，請隨時透過 Twitter 或 LinkedIn 與我聯繫。</font></font></font></p></div><div class="pt-6 pb-6 text-sm text-gray-700 dark:text-gray-300" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6 data-immersive-translate-paragraph=1><a target=_blank rel=nofollow href="https://mobile.twitter.com/search?q=https%3A%2F%2Fwww.philschmid.de%2Finstruction-tune-llama-2" data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>Discuss on Twitter</a> • <a target=_blank rel="noopener noreferrer" href=hhttps://github.com/philschmid/philschmid-de-v2/blob/master/data/blog/instruction-tune-llama-2.mdx data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6>View on GitHub</a><font class="notranslate immersive-translate-target-wrapper" lang=zh-TW data-immersive-translate-translation-element-mark=1><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark=1><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark=1> 在 Twitter 上討論 • 在 GitHub 上查看</font></font></font></div></div></div></div></article></div></main><footer translate=no><div class="mt-16 flex flex-col items-center"><div class="mb-3 flex space-x-4"><a class="text-sm text-gray-500 transition hover:text-gray-600" target=_blank rel="noopener noreferrer" href=mailto:schmidphilipp1995@gmail.com><span class=sr-only>mail</span><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 20 20" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M2.003 5.884 10 9.882l7.997-3.998A2 2 0 0 0 16 4H4a2 2 0 0 0-1.997 1.884z"></path><path d="m18 8.118-8 4-8-4V14a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.118z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target=_blank rel="noopener noreferrer" href=https://github.com/philschmid><span class=sr-only>github</span><svg viewBox="0 0 24 24" xmlns=http://www.w3.org/2000/svg class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target=_blank rel="noopener noreferrer" href=https://www.linkedin.com/in/philipp-schmid-a6a2bb196/><span class=sr-only>linkedin</span><svg viewBox="0 0 24 24" xmlns=http://www.w3.org/2000/svg class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target=_blank rel="noopener noreferrer" href=https://twitter.com/_philschmid><span class=sr-only>twitter</span><svg xmlns=http://www.w3.org/2000/svg viewBox="0 0 24 24" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M23.953 4.57a10 10 0 0 1-2.825.775 4.958 4.958 0 0 0 2.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 0 0-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 0 0-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 0 1-2.228-.616v.06a4.923 4.923 0 0 0 3.946 4.827 4.996 4.996 0 0 1-2.212.085 4.936 4.936 0 0 0 4.604 3.417 9.867 9.867 0 0 1-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 0 0 7.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0 0 24 4.59z"></path></svg></a></div><div class="mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400"><div>Philipp Schmid</div><div> • </div><div>© 2024</div><div> • </div><a href=https://www.philschmid.de/>philschmid blog</a><div> • </div><div> • </div><a href=https://www.philschmid.de/imprint>Imprint</a></div></div></footer></div></div></div><next-route-announcer data-immersive-translate-walked=696dcf58-798c-4407-a34b-33aa0e13d7f6><p aria-live=assertive id=__next-route-announcer__ role=alert style=border:0px;clip:rect(0px,0px,0px,0px);height:1px;margin:-1px;overflow:hidden;padding:0px;position:absolute;width:1px;white-space:nowrap;overflow-wrap:normal></p></next-route-announcer>
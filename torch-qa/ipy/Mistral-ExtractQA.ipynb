{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers trl accelerate torch bitsandbytes peft datasets -qU\n",
    "#pip install scipy\n",
    "#torch==2.1.2\n",
    "#transformers==4.36.0\n",
    "#trl==0.7.4\n",
    "#accelerate==0.25.0\n",
    "#bitsandbytes==0.41.3.post2\n",
    "#peft==0.7.0\n",
    "#datasets==2.15.0\n",
    "#scipy==1.11.4\n",
    "#sentencepiece==0.1.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_standard.langchain_lit import load_all_documents\n",
    "\n",
    "docs = load_all_documents('./data-user/', 1000 * 7)\n",
    "\n",
    "def read_page_contents_from_docs(docs):\n",
    "   for doc in docs:\n",
    "      yield doc.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U spacy\n",
    "#python -m spacy download en_core_web_lg==3.7.1\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def read_file_segments(file_path):\n",
    "   with open(file_path, 'r', encoding='utf-8') as file:\n",
    "      text = file.read()\n",
    "   doc = nlp(text)\n",
    "   for sentence in doc.sents:\n",
    "      yield sentence.text\n",
    "\n",
    "a = list(read_file_segments('./documents/live-baccarat-doc.md'))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3791723d24b481b87f8dff36f8e7708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_PATH = f\"../models/Mistral-7B-Instruct-v0.2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    quantization_config=nf4_config,\n",
    "    device_map='auto',\n",
    "    local_files_only=True,\n",
    "    #trust_remote_code=False,\n",
    "    use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> [INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> [INST] Do you have mayonnaise recipes? [/INST]While I don't have the ability to create or prepare recipes myself, I can certainly help you find one for mayonnaise! Here's a classic and simple Homemade Mayonnaise recipe you can try:\\n\\nIngredients:\\n- 1 cup (240 ml) light tasting oil (like canola, safflower, or vegetable oil)\\n- 1 large egg yolk\\n- 1 tablespoon (15 ml) white wine vinegar or other mild vinegar\\n- 1 teaspoon (5 g) Dijon mustard\\n- 1/2 teaspoon (3 g) Kosher salt\\n- 1/2 teaspoon (3 g) Freshly ground black pepper\\n\\nInstructions:\\n1. Set up a large bowl with an immersion blender. This will make the process simpler. However, you can also use a regular blender or a whisk.\\n2. Add the egg yolk, vinegar, Dijon mustard, salt, and pepper to the bowl.\\n3. With the immersion blender at the bottom, drizzle the oil into the egg mixture in a slow but steady stream. Turn on the blender and blend the oil and egg mixture together until you have a thick, creamy mayonnaise. The oil should be fully incorporated before adding more.\\n4. Taste the mayonnaise and adjust seasoning if needed. Add any additional herbs, spices or other ingredients according to your preference.\\n5. Store the mayonnaise in an airtight container in the refrigerator. It will keep for up to one week.\\n\\nLet me know if this helps, or if you have any other questions!</s>\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask1():\n",
    "   global model, tokenizer\n",
    "   messages = [\n",
    "      {\"role\": \"user\", \"content\": \"What is your favourite condiment?\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!\"},\n",
    "      {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n",
    "   ]\n",
    "   model_inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(model.device)\n",
    "   generated_ids = model.generate(model_inputs, \n",
    "                                  max_new_tokens=1000, \n",
    "                                  do_sample=True,\n",
    "                                  pad_token_id=tokenizer.pad_token_id)\n",
    "   decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "   #print(decoded_output[0])\n",
    "   return decoded_output[0]\n",
    "\n",
    "answer = ask1()\n",
    "answer\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have a name. I'm just a computer program designed to help answer questions. You can call me AI or my friend, the assistant. How may I help you today?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lstrip_inst(text):\n",
    "   token = \"[/INST]\"\n",
    "   idx = text.rfind(token)\n",
    "   if idx != -1:\n",
    "      extracted_text = text[idx + len(token):]\n",
    "      return extracted_text.lstrip()\n",
    "   return text\n",
    "\n",
    "def rstrip_s(text):\n",
    "   token = \"</s>\"\n",
    "   idx = text.rfind(token)\n",
    "   if idx != -1:\n",
    "      extracted_text = text[:idx]\n",
    "      return extracted_text\n",
    "   return text\n",
    "\n",
    "\n",
    "def ask(user_input):\n",
    "   global model, tokenizer\n",
    "   messages = [\n",
    "      {\"role\": \"user\", \"content\": user_input}\n",
    "   ]\n",
    "   model_inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(model.device)\n",
    "   generated_ids = model.generate(model_inputs, \n",
    "                                  max_new_tokens=1000, \n",
    "                                  do_sample=True,\n",
    "                                  pad_token_id=tokenizer.pad_token_id)\n",
    "   decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "   answer = decoded_output[0]\n",
    "   answer = lstrip_inst(answer)\n",
    "   return rstrip_s(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask(\"what is your name?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_markdown_tables_from_content(page_content):\n",
    "   prompt = f\"\"\"{page_content}\n",
    "   ----------\n",
    "   Extract the Markdown table data and its related content from the above content,\n",
    "   and directly describe the data and related content in English.\n",
    "   \"\"\"\n",
    "   answer_markdown = ask(prompt)\n",
    "   return answer_markdown\n",
    "\n",
    "def generate_qa_from_markdown_tables(markdown_content):\n",
    "   prompt_template = \"\"\"{content}\n",
    "   ----------\n",
    "   Based on the above content, extract the Markdown table data and its related content,\n",
    "   and generate corresponding questions and answers directly.\n",
    "   Response Format:\n",
    "   Question: What is your name?\n",
    "   Answer: My name is Astro.\n",
    "   \"\"\"\n",
    "   prompt = prompt_template.format(content=markdown_content)\n",
    "   return ask(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_from_markdown_table_rows(markdown_content):\n",
    "   prompt_template = \"\"\"{content}\n",
    "   ----------\n",
    "   Based on the above content,\n",
    "   extract each row of data from the Markdown table data,\n",
    "   and generate corresponding questions and answers for each individual row directly.\n",
    "   Response Format:\n",
    "   Question: What is your name?\n",
    "   Answer: My name is Astro.\n",
    "   \"\"\"\n",
    "   prompt = prompt_template.format(content=markdown_content)\n",
    "   return ask(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_from_extract_terms(page_content):\n",
    "   prompt_template = \"\"\"{content}\n",
    "   ----------\n",
    "   Extract all the common terms from the above content and generate corresponding questions and answers for each one directly.\n",
    "   Response Format:\n",
    "   Question: What is your name?\n",
    "   Answer: My name is Astro.\n",
    "   \"\"\"\n",
    "   prompt = prompt_template.format(content=page_content)\n",
    "   return ask(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_from_extract_summary(page_content):\n",
    "   prompt_template = \"\"\"{content}\n",
    "   ----------\n",
    "   Summarize the above content and then generate corresponding questions and answers directly.\n",
    "   Response Format:\n",
    "   Question: What is your name?\n",
    "   Answer: My name is Astro.\n",
    "   \"\"\"\n",
    "   prompt = prompt_template.format(content=page_content)\n",
    "   return ask(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_from_extract_segments(page_content):\n",
    "   prompt_template = \"\"\"{content}\n",
    "   ----------\n",
    "   Segment the above content into appropriate paragraphs,\n",
    "   summarize each segment, Do not output summary, and then generate corresponding questions and answers for each segment directly.\n",
    "   Response Format:\n",
    "   Question: What is your name?\n",
    "   Answer: My name is Astro.\n",
    "   \"\"\"\n",
    "   prompt = prompt_template.format(content=page_content)\n",
    "   return ask(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_from_extract_values(page_content):\n",
    "   prompt_template = \"\"\"{content}\n",
    "   ----------\n",
    "   Extract each sentence related to numbers from the above content and generate corresponding question-answer pairs directly.\n",
    "   Response Format:\n",
    "   Question: What is your name?\n",
    "   Answer: My name is Astro.\n",
    "   \"\"\"\n",
    "   prompt = prompt_template.format(content=page_content)\n",
    "   return ask(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question: What is the objective of Live Dealer Baccarat?\\nAnswer: The objective of Live Dealer Baccarat is to bet on which hand, the player's or the banker's, will have a point value closest to 9.\\n\\nQuestion: How is the game presented to the Player?\\nAnswer: The game is presented to the Player with a live person dealing the cards on screen to provide the Player with a realistic gaming environment in real time.\\n\\nQuestion: What is the theoretical return to player of this game?\\nAnswer: The theoretical return to player of this game is 98.41%.\\n\\nQuestion: How do Players place bets?\\nAnswer: Players place their bets by moving the cursor to the pictures of the chips, left-clicking to select the chip value, and then moving the cursor to the Betting Area on the table layout to place the bet.\\n\\nQuestion: What is the value of cards in Live Dealer Baccarat?\\nAnswer: All cards are recalculated to have a value closest to 9, with no values greater than nine. Card values are determined by subtracting ten from the combined value every time it reaches a number greater than nine.\\n\\nQuestion: What happens if both hands have the same point value in Live Dealer Baccarat?\\nAnswer: In the case of a tie, neither side wins or loses, but tie bets win.\\n\\nQuestion: What is Dragon Bonus in Live Dealer Baccarat?\\nAnswer: Dragon Bonus is a side bet in Live Dealer Baccarat that pays when the chosen hand has a natural win or when the chosen hand wins by at least 4 points difference (non-natural).\\n\\nQuestion: What is Fortune Six in Live Dealer Baccarat?\\nAnswer: Fortune Six is a side bet in Live Dealer Baccarat that pays if the Banker hand wins with a total of six.\\n\\nQuestion: What are Tiger bets in Live Dealer Baccarat?\\nAnswer: Tiger bets are optional wagers in Live Dealer Baccarat that pay if the Banker hand wins with a total of six. There are five types of Tiger bets, each with different odds depending on how many cards the Banker has when the hand is complete.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = generate_qa_from_extract_values(docs1)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_qa_file(file_path, text, mode=\"a\"):\n",
    "   with open(file_path, mode, encoding='utf-8') as f:\n",
    "      f.write(text)\n",
    "      \n",
    "def generate_qa_from_page_content(page_content):\n",
    "   qa_content = \"\"\n",
    "   qa_content += generate_qa_from_extract_summary(page_content)\n",
    "   qa_content += \"\\r\\n##########\\r\\n\"\n",
    "   qa_content = generate_qa_from_extract_segments(page_content)\n",
    "   qa_content += \"\\r\\n##########\\r\\n\"\n",
    "   qa_content = generate_qa_from_extract_terms(page_content)\n",
    "   qa_content += \"\\r\\n##########\\r\\n\"\n",
    "   markdown_content = extract_markdown_tables_from_content(page_content)\n",
    "   qa_content = generate_qa_from_markdown_tables(markdown_content)\n",
    "   qa_content += \"\\r\\n##########\\r\\n\"\n",
    "   qa_content = generate_qa_from_markdown_table_rows(markdown_content)\n",
    "   qa_content += \"\\r\\n##########\\r\\n\"\n",
    "   qa_content = generate_qa_from_extract_values(page_content)\n",
    "   qa_content += \"\\r\\n##########\\r\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(docs):\n",
    "   mode = \"w\" if idx == 0 else \"a\"\n",
    "   qa_content = generate_qa_from_page_content(doc.page_content)\n",
    "   write_qa_file('./results/llm-qa1.md', text=qa_content, mode=mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

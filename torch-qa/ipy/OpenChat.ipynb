{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers trl accelerate torch bitsandbytes peft datasets -qU\n",
    "#pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128d0289d3374fccad16367a4c770067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flash/miniconda3/envs/torch/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = f\"../models/openchat-3.5-1210\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    quantization_config=nf4_config,\n",
    "    device_map='auto',\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=False,\n",
    "    use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "#tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deci_generator = pipeline(\"text-generation\",\n",
    "                          model=model,\n",
    "                          tokenizer=tokenizer,\n",
    "                          temperature=0.1,\n",
    "                          device_map=\"auto\",\n",
    "                          max_length=1024,\n",
    "                          return_full_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(user_input):\n",
    "   #GPT4 Correct User: Hello<|end_of_turn|>GPT4 Correct Assistant: Hi<|end_of_turn|>GPT4 Correct User: How are you today?<|end_of_turn|>GPT4 Correct Assistant:\n",
    "   SYSTEM_PROMPT_TEMPLATE =\"\"\"GPT4 Correct User: {user_input}<|end_of_turn|>GPT4 Correct Assistant: \"\"\"\n",
    "   prompt = SYSTEM_PROMPT_TEMPLATE.format(user_input=user_input)\n",
    "   inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "   output = model.generate(**inputs,\n",
    "                            max_new_tokens=500,\n",
    "                            num_beams=5,\n",
    "                            no_repeat_ngram_size=4,\n",
    "                            early_stopping=True,\n",
    "                            eos_token_id=tokenizer.eos_token_id, \n",
    "                            pad_token_id=tokenizer.eos_token_id, \n",
    "                            )\n",
    "   output = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "   ss = output.split('<|end_of_turn|>')[-2:]\n",
    "   ss = ''.join(ss).replace('GPT4 Correct Assistant: ', '').lstrip()\n",
    "   return ss\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flash/miniconda3/envs/torch/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My name is ChatGPT, a large language model created by OpenAI.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_qa(context, user_question):\n",
    "   prompt = \"\"\"\n",
    "Instruction: Answer the question based on following private context. \n",
    "The response content must appear within the private context.\n",
    "If the answer cannot be found from the following private context, respond with 'I don't know.'.\n",
    "Here is private context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "Here is QUESTION:\n",
    "{question} \n",
    "\"\"\"\n",
    "   return ask(prompt.format(context=context, question=user_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output='<s> GPT4 Correct User: \\nInstruction: Answer the question based on your gaming knowledge. \\nIf the answer cannot be found from the context, respond with \\'I don\\'t know.\\'.\\nHere is context to help:\\n\\n\\nQuestion: What is Depbon in the promo code?\\nAnswer: Depbon means deposit bonus.\\n\\nQuestion: What is ACE in the promo code?\\nAnswer: ACE means MNL Bonus for BET.\\nSouth Korea is an exception. South Korea players use the \\'TOP\\' promo code.\\n\\n\\nUser QUESTION:\\nWhat is ACE? \\n<|end_of_turn|> GPT4 Correct Assistant: \\nACE in a promo code typically stands for a bonus or promotion offered by an online gaming platform. In some cases, it may mean \"MNL Bonus\" for BET, while in South Korea, it may refer to the \"TOP\" promo code for players. The specific meaning may vary depending on the platform and region.<|end_of_turn|>'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ACE in a promo code typically stands for a bonus or promotion offered by an online gaming platform. In some cases, it may mean \"MNL Bonus\" for BET, while in South Korea, it may refer to the \"TOP\" promo code for players. The specific meaning may vary depending on the platform and region.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "Question: What is Depbon in the promo code?\n",
    "Answer: Depbon means deposit bonus.\n",
    "\n",
    "Question: What is ACE in the promo code?\n",
    "Answer: ACE means MNL Bonus for BET.\n",
    "South Korea is an exception. South Korea players use the 'TOP' promo code.\n",
    "\"\"\"\n",
    "\n",
    "answer = ask_qa(context, \"What is ACE?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "   with open(file, 'r', encoding='utf-8') as f:\n",
    "      return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = read_file('../fine-tune/data/Test.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Baccatat is a card game that is popular in casinos and involves players betting on the outcome of a hand between the Player and the Banker. The goal is to get a hand value as close to 9 as possible, with the use of specific rules determining if a third card is needed. The game is known for its straightforward rules and enticing atmosphere.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa(context, \"Introduce Baccarat\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Error Code Table\\nError Code | Description\\n---|----\\nE1000 | Unknown error\\nE2001 | Connection error\\nE3002 | Authentication error\\nE4003 | Authorization error\\nE5004 | Data error\\nE6005 | System error\\nE7006 | Interface error\\nE8007 | Side bet error\\nE9008 | Game rule error\\nEA009 | Audio error\\nEB00A | Video error\\nEC00B | Graphic error\\nED00C | Input error\\nEE00D | Output error\\nEF00E | Display error\\nEG00F | Environment error\\nEH00G | Hardware error\\nEI00H | Software error\\nEJ00I | Communication error\\nEK00J | Network error\\nEL00K | Location error\\nEM00L | Language error\\nEN00M | Currency error\\nEO00N | Time error\\nEP00O | Odds error\\nEQ00P | Privacy error\\nER00Q | Regulation error\\nES00R | Security error\\nET00S | Troubleshooting error\\nEU00T | Update error\\nEV00U | User error\\nEW00V | Warranty error\\nEX00X | Miscellaneous error\\nEY00Y | Custom error\\nEZ00Z | Reserved error\\n\\nBased on the private context provided, I don't have enough information to answer the question about error code E0000.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa(context, \"What is error code E8000?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The private context discusses odds tables for two games, SEC Game and MAYA game. The SEC Game odds table includes three entries with their respective average scores, while the MAYA Games odds table lists the same three entries with the same average scores. The context also introduces the game of Baccatat, explaining its basic rules and its popularity among players. Finally, it introduces Tiger Bacarrat as a modification of the original game, offering additional side bets for players.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa(context, \"Summarize the content.\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The odds table for the MAYA game is as follows:\\n\\n1. Mistral‑T5‑7B‑v1 has an odds of 12.\\n2. openchat‑3.5‑12.10 has odds of 35.\\n3. mistral‑7b‑instruct‑v.0.2 has a odds of 57.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa(context, \"What is odds of MAYA Game?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The percentage Table of the SEC Game shows the average percentage for each player in the game. Based on the provided private context, the percentages are as follows:\\n\\n- Player A has an average of 67.1%\\n- Player B has a 59.2% average\\n- Player C has a 49.3% average'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa(context, \"what is percentage Table of SEC Game?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask_qa(context, \"Generate several questions and answers based on the content, with each answer contained within the private context. The cumulative content of all answers must cover over 90% of the private context.\")\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

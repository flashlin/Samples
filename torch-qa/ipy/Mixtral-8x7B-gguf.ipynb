{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence_transformers\n",
    "# pip install langchain\n",
    "# pip install pypdf\n",
    "# pip install typing-extensions==4.8.0\n",
    "# pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA RTX A6000, compute capability 8.6\n",
      "llama_model_loader: loaded meta data with 25 key-value pairs and 995 tensors from /home/flash/models/dolphin-2.5-mixtral-8x7b.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = ehartford_dolphin-2.5-mixtral-8x7b\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:                         llama.expert_count u32              = 8\n",
      "llama_model_loader: - kv  10:                    llama.expert_used_count u32              = 2\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  13:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:   32 tensors\n",
      "llama_model_loader: - type q8_0:   64 tensors\n",
      "llama_model_loader: - type q4_K:  833 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 8\n",
      "llm_load_print_meta: n_expert_used    = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 46.70 B\n",
      "llm_load_print_meta: model size       = 24.62 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = ehartford_dolphin-2.5-mixtral-8x7b\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.38 MiB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: system memory used  =   70.70 MiB\n",
      "llm_load_tensors: VRAM used           = 25145.56 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 32768\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  = 4096.00 MiB, K (f16): 2048.00 MiB, V (f16): 2048.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 1124/1124\n",
      "llama_new_context_with_model: compute buffer total size = 2167.22 MiB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 2164.04 MiB\n",
      "llama_new_context_with_model: total VRAM used: 27309.60 MiB (model: 25145.56 MiB, context: 2164.04 MiB)\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "MODEL_PATH = \"../models/dolphin-2.5-mixtral-8x7b.Q4_K_M.gguf\"\n",
    "MODEL_PATH = \"/home/flash/models/dolphin-2.5-mixtral-8x7b.Q4_K_M.gguf\"\n",
    "# 38min\n",
    "# 40s\n",
    "llm = LlamaCpp(\n",
    "    model_path=MODEL_PATH,\n",
    "    n_ctx=1024 * 32,\n",
    "    n_gpu_layers=40,\n",
    "    n_threads=15,\n",
    "    n_batch=512,\n",
    "    f16_kv=True,\n",
    "    #callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"I'm a QA expert, I'll respond only to answers I'm confident in, and for ones I'm not sure about, I'll simply say 'I don't know'.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(user_input):\n",
    "   prompt = prompt_template.format(system_prompt=system_prompt, user_prompt=user_input)\n",
    "   resp = llm(prompt,  \n",
    "      max_tokens=2048,\n",
    "      temperature=0.7,\n",
    "      top_p=0.1,\n",
    "      repeat_penalty=1.1)\n",
    "   return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1002.43 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /     7 runs   (    0.35 ms per token,  2836.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1000.54 ms /    63 tokens (   15.88 ms per token,    62.97 tokens per second)\n",
      "llama_print_timings:        eval time =     275.20 ms /     6 runs   (   45.87 ms per token,    21.80 tokens per second)\n",
      "llama_print_timings:       total time =    1313.20 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I don't know.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask(\"What is your name?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "   with open(file, 'r', encoding='utf-8') as f:\n",
    "      return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_standard.langchain_lit import split_documents, convert_docs_to_splits, LlmEmbedding\n",
    "from py_standard.pdf_utils import load_pdf_documents_from_directory\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "EMB_MODEL = \"bge-base-en\"\n",
    "def load_all_pdfs(path):\n",
    "   pdfs = load_pdf_documents_from_directory(path)\n",
    "   docs = split_documents(pdfs, 1000 * 10)\n",
    "   return docs\n",
    "   \n",
    "def load_vectorstore(docs):\n",
    "   llm_embedding = LlmEmbedding(f\"../models/{EMB_MODEL}\")\n",
    "   vectorstore = Chroma.from_documents(documents=docs,\n",
    "                                        embedding=llm_embedding.embedding)\n",
    "   return vectorstore\n",
    "   # retriever = vectorstore.as_retriever(\n",
    "   #   search_kwargs={'k': 3, 'fetch_k': 50}\n",
    "   # )\n",
    "   # return retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_all_pdfs('./pdfs')\n",
    "vectorstore = load_vectorstore(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split['source']='pdfs/Silverthorne Publications, Inc..pdf'\n",
      "split['source']='pdfs/Five-CountBaccarat-Book.pdf'\n",
      "split['source']='pdfs/Five-CountBaccarat-Book.pdf'\n",
      "split['source']='pdfs/Silverthorne Publications, Inc..pdf'\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Five-Count Baccarat?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "splits = convert_docs_to_splits(docs)\n",
    "for split in splits:\n",
    "   print(f\"{split['source']=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4797.80 ms\n",
      "llama_print_timings:      sample time =      24.02 ms /    65 runs   (    0.37 ms per token,  2705.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8929.96 ms /   895 tokens (    9.98 ms per token,   100.22 tokens per second)\n",
      "llama_print_timings:        eval time =    4940.68 ms /    64 runs   (   77.20 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:       total time =   14017.50 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n### ANSWER:\\n Five-Count Baccarat is a baccarat game system designed by George Stearn and published by Silverthorne Publications, Inc. The system claims to provide an easy-to-learn method for players to increase their chances of winning at baccarat.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "def create_qa_chain_prompt_template():\n",
    "    system_prompt = \"\"\"You are a helpful assistant, you will use the provided context to answer user questions.\n",
    "    Read the given context before answering questions and think step by step. If you can not answer a user question based on\n",
    "    the provided context, inform the user. Do not use any other information for answering user\"\"\"\n",
    "\n",
    "    prompt_template = \"\"\"Instruction: Answer the question based on following context. \n",
    "If the answer cannot be found from the following context, respond with 'I don't know.'.\n",
    "Here is context to help:\n",
    "\n",
    "{context}\n",
    "    \n",
    "### QUESTION:\n",
    "{question}\n",
    "    \"\"\"\n",
    "\n",
    "    qa_chain_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "    return qa_chain_prompt\n",
    "\n",
    "# Chain\n",
    "qa_chain = load_qa_chain(\n",
    "    llm,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=create_qa_chain_prompt_template()\n",
    ")\n",
    "\n",
    "# Run\n",
    "question = \"What is Five-Count Baccarat?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "result = qa_chain({\n",
    "    \"input_documents\": docs,\n",
    "    \"question\": question\n",
    "    },\n",
    "    return_only_outputs=True\n",
    ")\n",
    "\n",
    "# Output\n",
    "result['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = read_file('./data/baccarat-book.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(text, length):\n",
    "    return [text[i:i+length] for i in range(0, len(text), length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_splits = split_string(context, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1408.84 ms\n",
      "llama_print_timings:      sample time =      93.50 ms /   256 runs   (    0.37 ms per token,  2737.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21537.70 ms /  1750 tokens (   12.31 ms per token,    81.25 tokens per second)\n",
      "llama_print_timings:        eval time =   30391.78 ms /   255 runs   (  119.18 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =   52509.51 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Baccarat is a popular card game played in casinos around the world. The objective of the game is for the player to predict whether the value of their hand will be closer to or equal to the value of the banker's hand. The game is usually played with eight decks of cards, and the value of each card is determined as follows: an ace counts as 1 point, a two through nine count as the face value of the card (for example, a seven counts as 7 points), and a ten or face card (king, queen) counts as 0 points. The total value of each player's hand is then calculated by adding together the values of all of the cards in that player's hand. For example, if a player was holding a two and an ace, the total value of their hand would be calculated as follows: 2 (two) + 1 (ace) = 3 points. Similarly, if a player was holding a seven and an eight, the total value of their hand would be calculated as follows: 7 (seven) + 8 (eight) = 15 points. However, since the game is usually played with eight decks of cards, and there are only two\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_prompt_template = \"\"\"Instruction: Answer the question based on following context. \n",
    "If the answer cannot be found from the following context, respond with 'I don't know.'.\n",
    "Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### USER QUESTION:\n",
    "{question} \n",
    "\"\"\"\n",
    "\n",
    "prompt = qa_prompt_template.format(context=context_splits[0],question=\"What is baccarat?\")\n",
    "answer = ask(prompt)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_qa(user_input):\n",
    "   prompt = qa_prompt_template.format(context=context_splits[0],question=user_input)\n",
    "   return ask(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1408.84 ms\n",
      "llama_print_timings:      sample time =      44.83 ms /   120 runs   (    0.37 ms per token,  2676.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.92 ms /    18 tokens (   64.72 ms per token,    15.45 tokens per second)\n",
      "llama_print_timings:        eval time =   13307.87 ms /   119 runs   (  111.83 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =   14733.31 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Contra-d'Alembert is a betting system in the game of roulette. The name itself is derived from French mathematician Jean le Rond d'Alembert. \\n\\nThe concept behind this betting system is contrary to that of the famous martingale betting system. Unlike the martingale system, which involves increasing your bets after losing rounds, Contra-d'Alembert requires you to decrease your bets after losing rounds and increase them after winning ones. This approach aims at minimizing losses while maximizing profits.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa(\"What is Contra-d'Alembert?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1408.84 ms\n",
      "llama_print_timings:      sample time =      31.19 ms /    84 runs   (    0.37 ms per token,  2693.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1074.32 ms /    15 tokens (   71.62 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =    8756.51 ms /    83 runs   (  105.50 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =   10017.74 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Tracker Betting is a betting strategy used in baccarat play. It involves tracking the results of each round of play to determine where to place bets for subsequent rounds of play. The goal of Tracker Betting is to identify patterns in the outcomes of each round of play and then use this information to make informed decisions about where to place bets in order to maximize profits and minimize losses.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa('What is \"Tracker Betting\"?')\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1408.84 ms\n",
      "llama_print_timings:      sample time =     745.15 ms /  2048 runs   (    0.36 ms per token,  2748.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1044.97 ms /    32 tokens (   32.66 ms per token,    30.62 tokens per second)\n",
      "llama_print_timings:        eval time =  334022.37 ms /  2047 runs   (  163.18 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:       total time =  342075.28 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' A: Sure, here are some questions and answers based on the context provided:\\n\\nQ1: What is Target Baccarat?\\nA1: Target Baccarat is a professional-level baccarat betting strategy that has never lost in over 10,000 documented games played by real players.\\nQ2: How does Target Baccarat work?\\nA2: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet and how much to bet. The strategy also includes a Unique Bet Timing System that is used to pick the optimal time to place each bet.\\n\\nQ3: What are some key features of Target Baccarat?\\nA3: Some key features of Target Baccarat include its ability to consistently produce explosive profits, its use of a combination of Target Betting and Tracker Betting to determine where to bet and how much to bet, its inclusion of a Unique Bet Timing System that is used to pick the optimal time to place each bet, and its overall ease of use and ability to be quickly learned and easily applied by both new and experienced baccarat players alike.\\n\\nQ4: How does Target Baccarat determine where to bet?\\nA4: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ5: How does Target Baccarat determine how much to bet?\\nA5: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ6: How does Target Baccarat use a Unique Bet Timing System to pick where to bet?\\nA6: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ7: How does Target Baccarat adjust the amounts bet using a Bet Sizing Strategy?\\nA7: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ8: How does Target Baccarat use a Unique Bet Timing System to pick the optimal time to place each bet?\\nA8: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ9: How does Target Baccarat use a Unique Bet Timing System to pick the optimal time to place each bet?\\nA9: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ10: How does Target Baccarat use a Unique Bet Timing System to pick the optimal time to place each bet?\\nA10: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ11: How does Target Baccarat use a Unique Bet Timing System to pick the optimal time to place each bet?\\nA11: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ12: How does Target Baccarat use a Unique Bet Timing System to pick the optimal time to place each bet?\\nA12: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ13: How does Target Baccarat use a Unique Bet Timing System to pick the optimal time to place each bet?\\nA13: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ14: How does Target Baccarat use a Unique Bet Timing System to pick the optimal time to place each bet?\\nA14: Target Baccarat uses a combination of Target Betting and Tracker Betting to determine where to bet, as well as how much to bet. The strategy first uses Target Betting to set up a predetermined profit target that is used as the basis for determining where to place each bet. The strategy then uses Tracker Betting to track and monitor the ongoing progress and performance of each individual bet that is placed during the course of play, in order to ensure that each individual bet that is placed is consistently producing optimal results and outcomes in terms of maximizing profits and minimizing losses for each individual bet that is placed.\\n\\nQ15: How does Target Baccarat use a Unique Bet Timing System to pick the optimal time to place each bet?\\nA15: Target Baccarat uses a combination of Target'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa('Generate many questions(Q:) and answers(A:), and the answers must be contained in the above content.')\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1408.84 ms\n",
      "llama_print_timings:      sample time =      33.60 ms /    89 runs   (    0.38 ms per token,  2648.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    9647.51 ms /    89 runs   (  108.40 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    9841.62 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Target Baccarat is a professional-level baccarat strategy that has never lost. It uses Target Betting, a system borrowed from stock trading, to set up winning bets. The strategy also determines the size of bets using a Unique Betting Strategy. Overall, Target Baccarat provides an easy-to-learn and use professional-level baccarat strategy that has never lost.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa('summarize the context')\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tune2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

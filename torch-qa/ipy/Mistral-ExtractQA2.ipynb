{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers trl accelerate torch bitsandbytes peft datasets -qU\n",
    "#pip install scipy\n",
    "#torch==2.1.2\n",
    "#transformers==4.36.0\n",
    "#trl==0.7.4\n",
    "#accelerate==0.25.0\n",
    "#bitsandbytes==0.41.3.post2\n",
    "#peft==0.7.0\n",
    "#datasets==2.15.0\n",
    "#scipy==1.11.4\n",
    "#sentencepiece==0.1.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def read_file_paragraphs(file_path, chunk_size=1000):\n",
    "   with open(file_path, 'r', encoding='utf-8') as file:\n",
    "      text = file.read()\n",
    "   doc = nlp(text)\n",
    "   buffer = \"\"\n",
    "   for sentence in doc.sents:\n",
    "      if sentence.text.startswith('#') and buffer != \"\":\n",
    "         yield buffer\n",
    "         buffer = \"\"\n",
    "      new_buffer = buffer + sentence.text\n",
    "      if len(new_buffer) >= chunk_size:\n",
    "         yield buffer\n",
    "         new_buffer = sentence.text\n",
    "      buffer = new_buffer\n",
    "   if buffer != \"\":\n",
    "      yield buffer\n",
    "      buffer = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for paragraph in read_file_paragraphs('./data-user/live-baccarat-doc.md'):\n",
    "   docs.append({\n",
    "      'page_content': paragraph.rstrip()\n",
    "   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flash/miniconda3/envs/tune2/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15374c166ab54f8c9f6136bdfb893ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PEFT ../fine-tune/outputs/Mistral-7B-Instruct-v0.1-qlora/\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from finetune_lit import load_peft_model\n",
    "\n",
    "BASE_MODEL_PATH = \"/home/flash/models/Mistral-7B-Instruct-v0.1\"\n",
    "PEFT_MODEL_PATH = \"../fine-tune/outputs/Mistral-7B-Instruct-v0.1-qlora/\"\n",
    "model, tokenizer = load_peft_model(BASE_MODEL_PATH, PEFT_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 1024 * 2\n",
    "generation_config.temperature = 0.01 \n",
    "generation_config.do_sample = True\n",
    "generation_config.top_k = 3\n",
    "generation_config.top_p = 0.75\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune_lit import ask_llama2_instruction_prompt\n",
    "\n",
    "def ask(user_input):\n",
    "   global model, tokenizer, generation_config\n",
    "   answer = ask_llama2_instruction_prompt(model=model,\n",
    "                                          generation_config=generation_config,\n",
    "                                          tokenizer=tokenizer,\n",
    "                                          device=model.device,\n",
    "                                          question=user_input)\n",
    "   return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' My name is Mistral 7B v0.1. But you can just call me Mistral.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask(\"what is your name?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_from_page_content(title, page_content):\n",
    "   prompt_template = \"\"\"extract {title} into Q&A data.\n",
    "{page_content}\"\"\"   \n",
    "   prompt = prompt_template.format(title=title, page_content=page_content)\n",
    "   return ask(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Introduction to Live Dealer Baccarat\\n\\nThe objective of the game is to bet on whichever of two hands, the player's hand or the banker's hand, that the Player thinks will have a point value closest to 9.The Player can also bet on a tie.\\n\\nThe game is presented to the Player with a live person dealing the cards on screen to provide the Player with a realistic gaming environment in real time.\\n\\nThe theoretical return to player of this game is 98.41%.\\nOver a long period of time, the game is likely to average a return to the Player of 98.48% of the total bets made.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_content = docs[0]['page_content']\n",
    "page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Question: What is Live Dealer Baccarat?\\nAnswer: The objective of the game is to bet on whichever of two hands, the player's hand or the banker's hand, that the Player thinks will have a point value closest to 9.The Player can also bet on a tie.\\n\\nThe game is presented to the Player with a live person dealing the cards on screen to provide the Player with a realistic gaming environment in real time.\\n\\nThe theoretical return to player of this game is 98.41%.\\nOver a long period of time, the game is likely to average a return to the Player of 98.48% of the total bets made.\\n\\nQuestion: In Live Dealer Baccarat, what is the objective?\\nAnswer: The objective of the game is to bet on whichever of two hands, the player's hand or the banker's hand, that the Player thinks will have a point value closest to 9.The Player can also bet on a tie.\\n\\nQuestion: In Live Dealer Baccarat, who deals the cards?\\nAnswer: The game is presented to the Player with a live person dealing the cards on screen to provide the Player with a realistic gaming environment in real time.\\n\\nQuestion: In Live Dealer Baccarat, what is the theoretical return to player?\\nAnswer: The theoretical return to player of this game is 98.41%.\\n\\nQuestion: In Live Dealer Baccarat, over a long period of time, what is the average return to the Player?\\nAnswer: Over a long period of time, the game is likely to average a return to the Player of 98.48% of the total bets made.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = generate_qa_from_page_content(\"Live Dealer Baccarat\", page_content)\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

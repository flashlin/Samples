{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q fairseq2==0.1.0 gradio==3.40.1\n",
    "#!pip install -q git+https://github.com/camenduru/seamless_communication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git clone -b dev https://github.com/camenduru/seamless_m4t-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fairseq2==0.1 pydub yt-dlp\n",
    "%git clone https://github.com/facebookresearch/seamless_communication.git\n",
    "%cd seamless_communication\n",
    "%git checkout 01c1042841f9bce66902eb2c7512dbdd71d42112 # We will use a stable version; if you want to use the latest version, comment out this line.\n",
    "%pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://github.com/facebookresearch/seamless_communication.git\n",
    "# copy seamless_communication/src 裡面的 seamless_communication 資料夾到 /ipy/ 目錄\n",
    "#pip install torch==2.1.1 \n",
    "#pip install torchaudio\n",
    "#%pip install fairseq2==0.2 pydub yt-dlp\n",
    "#conda install -c conda-forge libsndfile==1.0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seamless_communication.inference import Translator\n",
    "from IPython.display import Audio\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub import AudioSegment\n",
    "import torchaudio\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_with_max_duration(input_file, output_directory, min_silence_len=2500, silence_thresh=-60, max_chunk_duration=15000):\n",
    "    sound = AudioSegment.from_wav(input_file)\n",
    "    # Splitting on silence\n",
    "    audio_chunks = split_on_silence(sound, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    # split for max_chunk_duration\n",
    "    final_audio_chunks = []\n",
    "    for chunk in audio_chunks:\n",
    "        if len(chunk) > max_chunk_duration:\n",
    "            num_subchunks = len(chunk) // max_chunk_duration + 1\n",
    "            subchunk_size = len(chunk) // num_subchunks\n",
    "            for i in range(num_subchunks):\n",
    "                start_idx = i * subchunk_size\n",
    "                end_idx = (i + 1) * subchunk_size\n",
    "                subchunk = chunk[start_idx:end_idx]\n",
    "                final_audio_chunks.append(subchunk)\n",
    "        else:\n",
    "            final_audio_chunks.append(chunk)\n",
    "    # Export wav\n",
    "    for i, chunk in enumerate(final_audio_chunks):\n",
    "        output_file = f\"{output_directory}/chunk{i}.wav\"\n",
    "        print(\"Exporting file\", output_file)\n",
    "        chunk.export(output_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_play_audio(path_save, audio, sample_rate):\n",
    "    torchaudio.save(\n",
    "        path_save,\n",
    "        audio[0].cpu(),\n",
    "        sample_rate=sample_rate,\n",
    "    )\n",
    "\n",
    "    audio_play = Audio(path_save, rate=sample_rate, autoplay=True, normalize=True)\n",
    "    display(audio_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    dtype = torch.float16\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    dtype = torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssetNotFoundError",
     "evalue": "An asset with the name 'seamlessM4T_v2_large_local' cannot be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssetNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m translator \u001b[39m=\u001b[39m Translator(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     model_name_or_card\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseamlessM4T_v2_large_local\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     vocoder_name_or_card\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvocoder_v2\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     apply_mintox\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[0;32m/mnt/d/VDisk/Github/Samples/torch-qa/ipy/seamless_communication/inference/translator.py:93\u001b[0m, in \u001b[0;36mTranslator.__init__\u001b[0;34m(self, model_name_or_card, vocoder_name_or_card, device, text_tokenizer, apply_mintox, dtype, input_modality, output_modality)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model_name_or_card, \u001b[39mstr\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m     model_name_or_card \u001b[39m=\u001b[39m asset_store\u001b[39m.\u001b[39;49mretrieve_card(model_name_or_card)\n\u001b[1;32m     95\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model_name_or_card, AssetCard)\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m input_modality \u001b[39mor\u001b[39;00m output_modality:\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.11/site-packages/fairseq2/assets/store.py:60\u001b[0m, in \u001b[0;36mProviderBackedAssetStore.retrieve_card\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`name` must not contain the reserved \u001b[39m\u001b[39m'\u001b[39m\u001b[39m@\u001b[39m\u001b[39m'\u001b[39m\u001b[39m character.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m envs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_envs()\n\u001b[0;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_retrieve_card(name, envs)\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.11/site-packages/fairseq2/assets/store.py:77\u001b[0m, in \u001b[0;36mProviderBackedAssetStore._do_retrieve_card\u001b[0;34m(self, name, envs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_retrieve_card\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m, envs: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AssetCard:\n\u001b[0;32m---> 77\u001b[0m     metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_metadata(name)\n\u001b[1;32m     79\u001b[0m     \u001b[39m# If we have environment-specific metadata, merge it with `metadata`.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[39mfor\u001b[39;00m env \u001b[39min\u001b[39;00m envs:\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.11/site-packages/fairseq2/assets/store.py:123\u001b[0m, in \u001b[0;36mProviderBackedAssetStore._get_metadata\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[39mexcept\u001b[39;00m AssetNotFoundError:\n\u001b[1;32m    121\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[39mraise\u001b[39;00m AssetNotFoundError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn asset with the name \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m cannot be found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssetNotFoundError\u001b[0m: An asset with the name 'seamlessM4T_v2_large_local' cannot be found."
     ]
    }
   ],
   "source": [
    "translator = Translator(\n",
    "    model_name_or_card=\"seamlessM4T_v2_large_local\",\n",
    "    vocoder_name_or_card=\"vocoder_v2\",\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    "    apply_mintox=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the video\n",
    "video_url = 'www.youtube.com/watch?v=g_9rPvbENUw'\n",
    "!yt-dlp -f \"mp4\"  --force-overwrites --max-downloads 1 --no-warnings --no-abort-on-error --ignore-no-formats-error --restrict-filenames -o Video.mp4  $video_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to wav\n",
    "!ffmpeg -y -i Video.mp4 -vn -acodec pcm_s16le -ar 44100 -ac 2 audio.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_file = \"/content/seamless_communication/audio.wav\"\n",
    "output_directory = \"/content/seamless_communication/split_segments\"\n",
    "\n",
    "!mkdir split_segments\n",
    "!rm -rf /content/seamless_communication/split_segments/*\n",
    "split_audio_with_max_duration(input_audio_file, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a split\n",
    "audio_path = '/content/seamless_communication/split_segments/chunk1.wav'\n",
    "audio = Audio(audio_path, rate=44100, autoplay=True, normalize=True)\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Speech to Speech Translate\n",
    "translated_text, wav, sr = translator.predict(\n",
    "    input='/content/seamless_communication/split_segments/chunk1.wav',\n",
    "    task_str='s2st',\n",
    "    tgt_lang='eng', # target language\n",
    "    src_lang='spa', # source language # If you specify this, it will improve the model's result.\n",
    "    spkr= -1,\n",
    ")\n",
    "\n",
    "# Save the audio and play\n",
    "save_and_play_audio(\n",
    "    '/content/seamless_communication/audiot.wav',\n",
    "    wav,\n",
    "    sr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will translate all the segments and combine them into a new audio file.\n",
    "segments = []\n",
    "\n",
    "for filename in sorted(os.listdir(output_directory)):\n",
    "    if filename.startswith(\"chunk\") and filename.endswith(\".wav\"):\n",
    "        segment_path = os.path.join(output_directory, filename)\n",
    "\n",
    "        translated_text, wav, sr = translator.predict(\n",
    "            input=segment_path,\n",
    "            task_str='s2st',\n",
    "            tgt_lang='eng',\n",
    "            src_lang='spa',\n",
    "        )\n",
    "        print(translated_text, segment_path)\n",
    "\n",
    "        torchaudio.save(\n",
    "            segment_path,\n",
    "            wav[0].cpu(),\n",
    "            sample_rate=sr,\n",
    "        )\n",
    "\n",
    "        segment = AudioSegment.from_file(segment_path)\n",
    "        segments.append(segment)\n",
    "\n",
    "    combined_audio = sum(segments)\n",
    "    combined_audio.export('/content/seamless_communication/audio_eng.mp3', format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/content/seamless_communication/audio_eng.mp3'\n",
    "audio = Audio(audio_path, rate=44100, autoplay=True, normalize=True)\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text to Speech Translate\n",
    "text = 'En el bosque encantado'\n",
    "translated_text, wav, sr = translator.predict(\n",
    "    text,\n",
    "    \"t2st\",\n",
    "    tgt_lang='eng',\n",
    "    src_lang='spa'\n",
    ")\n",
    "\n",
    "save_and_play_audio(\n",
    "    '/content/seamless_communication/text2speech.wav',\n",
    "    wav,\n",
    "    sr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to Text Translate\n",
    "text = 'En el bosque encantado, un zorro curioso halló un reloj antiguo. Al tocarlo, quedó atrapado en un bucle temporal. Buscó ayuda de un búho sabio, quien reveló que solo resolviendo acertijos podría romper el hechizo. Juntos descifraron enigmas, liberando al zorro y tejiendo una amistad eterna.'\n",
    "translated_text, _, _ = translator.predict(text, \"t2tt\", 'eng', src_lang='spa')\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speech to text translate\n",
    "# Resample audio\n",
    "resample_rate = 44100\n",
    "waveform, sample_rate = torchaudio.load('/content/seamless_communication/split_segments/chunk1.wav')\n",
    "resampler = torchaudio.transforms.Resample(sample_rate, resample_rate, dtype=waveform.dtype)\n",
    "resampled_waveform = resampler(waveform)\n",
    "torchaudio.save('/content/seamless_communication/split_segments/resample_chunk1.wav', resampled_waveform, resample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text, _, _ = translator.predict('/content/seamless_communication/split_segments/resample_chunk1.wav', \"s2tt\", 'eng')\n",
    "translated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

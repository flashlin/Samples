{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q fairseq2==0.1.0 gradio==3.40.1\n",
    "#!pip install -q git+https://github.com/camenduru/seamless_communication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git clone -b dev https://github.com/camenduru/seamless_m4t-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fairseq2==0.1 pydub yt-dlp\n",
    "%git clone https://github.com/facebookresearch/seamless_communication.git\n",
    "%cd seamless_communication\n",
    "%git checkout 01c1042841f9bce66902eb2c7512dbdd71d42112 # We will use a stable version; if you want to use the latest version, comment out this line.\n",
    "%pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seamless_communication'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mseamless_communication\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minference\u001b[39;00m \u001b[39mimport\u001b[39;00m Translator\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Audio\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydub\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioSegment\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seamless_communication'"
     ]
    }
   ],
   "source": [
    "from seamless_communication.models.inference import Translator\n",
    "from IPython.display import Audio\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub import AudioSegment\n",
    "import torchaudio\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_with_max_duration(input_file, output_directory, min_silence_len=2500, silence_thresh=-60, max_chunk_duration=15000):\n",
    "    sound = AudioSegment.from_wav(input_file)\n",
    "    # Splitting on silence\n",
    "    audio_chunks = split_on_silence(sound, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    # split for max_chunk_duration\n",
    "    final_audio_chunks = []\n",
    "    for chunk in audio_chunks:\n",
    "        if len(chunk) > max_chunk_duration:\n",
    "            num_subchunks = len(chunk) // max_chunk_duration + 1\n",
    "            subchunk_size = len(chunk) // num_subchunks\n",
    "            for i in range(num_subchunks):\n",
    "                start_idx = i * subchunk_size\n",
    "                end_idx = (i + 1) * subchunk_size\n",
    "                subchunk = chunk[start_idx:end_idx]\n",
    "                final_audio_chunks.append(subchunk)\n",
    "        else:\n",
    "            final_audio_chunks.append(chunk)\n",
    "    # Export wav\n",
    "    for i, chunk in enumerate(final_audio_chunks):\n",
    "        output_file = f\"{output_directory}/chunk{i}.wav\"\n",
    "        print(\"Exporting file\", output_file)\n",
    "        chunk.export(output_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_play_audio(path_save, audio, sample_rate):\n",
    "    torchaudio.save(\n",
    "        path_save,\n",
    "        audio[0].cpu(),\n",
    "        sample_rate=sample_rate,\n",
    "    )\n",
    "\n",
    "    audio_play = Audio(path_save, rate=sample_rate, autoplay=True, normalize=True)\n",
    "    display(audio_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(\n",
    "    \"seamlessM4T_large\",\n",
    "    \"vocoder_36langs\",\n",
    "    torch.device(\"cuda:0\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the video\n",
    "video_url = 'www.youtube.com/watch?v=g_9rPvbENUw'\n",
    "!yt-dlp -f \"mp4\"  --force-overwrites --max-downloads 1 --no-warnings --no-abort-on-error --ignore-no-formats-error --restrict-filenames -o Video.mp4  $video_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to wav\n",
    "!ffmpeg -y -i Video.mp4 -vn -acodec pcm_s16le -ar 44100 -ac 2 audio.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_file = \"/content/seamless_communication/audio.wav\"\n",
    "output_directory = \"/content/seamless_communication/split_segments\"\n",
    "\n",
    "!mkdir split_segments\n",
    "!rm -rf /content/seamless_communication/split_segments/*\n",
    "split_audio_with_max_duration(input_audio_file, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a split\n",
    "audio_path = '/content/seamless_communication/split_segments/chunk1.wav'\n",
    "audio = Audio(audio_path, rate=44100, autoplay=True, normalize=True)\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Speech to Speech Translate\n",
    "translated_text, wav, sr = translator.predict(\n",
    "    input='/content/seamless_communication/split_segments/chunk1.wav',\n",
    "    task_str='s2st',\n",
    "    tgt_lang='eng', # target language\n",
    "    src_lang='spa', # source language # If you specify this, it will improve the model's result.\n",
    "    spkr= -1,\n",
    ")\n",
    "\n",
    "# Save the audio and play\n",
    "save_and_play_audio(\n",
    "    '/content/seamless_communication/audiot.wav',\n",
    "    wav,\n",
    "    sr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will translate all the segments and combine them into a new audio file.\n",
    "segments = []\n",
    "\n",
    "for filename in sorted(os.listdir(output_directory)):\n",
    "    if filename.startswith(\"chunk\") and filename.endswith(\".wav\"):\n",
    "        segment_path = os.path.join(output_directory, filename)\n",
    "\n",
    "        translated_text, wav, sr = translator.predict(\n",
    "            input=segment_path,\n",
    "            task_str='s2st',\n",
    "            tgt_lang='eng',\n",
    "            src_lang='spa',\n",
    "        )\n",
    "        print(translated_text, segment_path)\n",
    "\n",
    "        torchaudio.save(\n",
    "            segment_path,\n",
    "            wav[0].cpu(),\n",
    "            sample_rate=sr,\n",
    "        )\n",
    "\n",
    "        segment = AudioSegment.from_file(segment_path)\n",
    "        segments.append(segment)\n",
    "\n",
    "    combined_audio = sum(segments)\n",
    "    combined_audio.export('/content/seamless_communication/audio_eng.mp3', format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/content/seamless_communication/audio_eng.mp3'\n",
    "audio = Audio(audio_path, rate=44100, autoplay=True, normalize=True)\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text to Speech Translate\n",
    "text = 'En el bosque encantado'\n",
    "translated_text, wav, sr = translator.predict(\n",
    "    text,\n",
    "    \"t2st\",\n",
    "    tgt_lang='eng',\n",
    "    src_lang='spa'\n",
    ")\n",
    "\n",
    "save_and_play_audio(\n",
    "    '/content/seamless_communication/text2speech.wav',\n",
    "    wav,\n",
    "    sr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to Text Translate\n",
    "text = 'En el bosque encantado, un zorro curioso halló un reloj antiguo. Al tocarlo, quedó atrapado en un bucle temporal. Buscó ayuda de un búho sabio, quien reveló que solo resolviendo acertijos podría romper el hechizo. Juntos descifraron enigmas, liberando al zorro y tejiendo una amistad eterna.'\n",
    "translated_text, _, _ = translator.predict(text, \"t2tt\", 'eng', src_lang='spa')\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speech to text translate\n",
    "# Resample audio\n",
    "resample_rate = 44100\n",
    "waveform, sample_rate = torchaudio.load('/content/seamless_communication/split_segments/chunk1.wav')\n",
    "resampler = torchaudio.transforms.Resample(sample_rate, resample_rate, dtype=waveform.dtype)\n",
    "resampled_waveform = resampler(waveform)\n",
    "torchaudio.save('/content/seamless_communication/split_segments/resample_chunk1.wav', resampled_waveform, resample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text, _, _ = translator.predict('/content/seamless_communication/split_segments/resample_chunk1.wav', \"s2tt\", 'eng')\n",
    "translated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

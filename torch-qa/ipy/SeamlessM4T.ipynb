{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q fairseq2==0.1.0 gradio==3.40.1\n",
    "#!pip install -q git+https://github.com/camenduru/seamless_communication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git clone -b dev https://github.com/camenduru/seamless_m4t-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install fairseq2==0.1 pydub yt-dlp\n",
    "# %git clone https://github.com/facebookresearch/seamless_communication.git\n",
    "# %cd seamless_communication\n",
    "# %git checkout 01c1042841f9bce66902eb2c7512dbdd71d42112 # We will use a stable version; if you want to use the latest version, comment out this line.\n",
    "# %pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://github.com/facebookresearch/seamless_communication.git\n",
    "# copy seamless_communication/src 裡面的 seamless_communication 資料夾到 /ipy/ 目錄\n",
    "#pip install torch==2.1.1 \n",
    "#pip install torchaudio\n",
    "#%pip install fairseq2==0.2 pydub yt-dlp\n",
    "#conda install -c conda-forge libsndfile==1.0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seamless_communication.inference import Translator\n",
    "from IPython.display import Audio\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "from pydub import AudioSegment\n",
    "import torchaudio\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_with_max_duration(input_file, output_directory, min_silence_len=2500, silence_thresh=-60, max_chunk_duration=15000):\n",
    "    sound = AudioSegment.from_wav(input_file)\n",
    "    # Splitting on silence\n",
    "    audio_chunks = split_on_silence(sound, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "    # split for max_chunk_duration\n",
    "    final_audio_chunks = []\n",
    "    for chunk in audio_chunks:\n",
    "        if len(chunk) > max_chunk_duration:\n",
    "            num_subchunks = len(chunk) // max_chunk_duration + 1\n",
    "            subchunk_size = len(chunk) // num_subchunks\n",
    "            for i in range(num_subchunks):\n",
    "                start_idx = i * subchunk_size\n",
    "                end_idx = (i + 1) * subchunk_size\n",
    "                subchunk = chunk[start_idx:end_idx]\n",
    "                final_audio_chunks.append(subchunk)\n",
    "        else:\n",
    "            final_audio_chunks.append(chunk)\n",
    "    # Export wav\n",
    "    for i, chunk in enumerate(final_audio_chunks):\n",
    "        output_file = f\"{output_directory}/chunk{i}.wav\"\n",
    "        print(\"Exporting file\", output_file)\n",
    "        chunk.export(output_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_play_audio(path_save, audio, sample_rate):\n",
    "    torchaudio.save(\n",
    "        path_save,\n",
    "        audio[0].cpu(),\n",
    "        sample_rate=sample_rate,\n",
    "    )\n",
    "\n",
    "    audio_play = Audio(path_save, rate=sample_rate, autoplay=True, normalize=True)\n",
    "    display(audio_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    dtype = torch.float16\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    dtype = torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of seamlessM4T_v2_large_local. Set `force` to `True` to download again.\n",
      "Using the cached etox dataset. Set `force` to `True` to download again.\n",
      "Using the cached tokenizer of mintox. Set `force` to `True` to download again.\n",
      "/home/flash/miniconda3/envs/whisper/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "translator = Translator(\n",
    "    model_name_or_card=\"seamlessM4T_v2_large_local\",\n",
    "    vocoder_name_or_card=\"vocoder_v2_local\",\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    "    apply_mintox=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the video\n",
    "video_url = 'www.youtube.com/watch?v=g_9rPvbENUw'\n",
    "!yt-dlp -f \"mp4\"  --force-overwrites --max-downloads 1 --no-warnings --no-abort-on-error --ignore-no-formats-error --restrict-filenames -o Video.mp4  $video_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to wav\n",
    "!ffmpeg -y -i Video.mp4 -vn -acodec pcm_s16le -ar 44100 -ac 2 audio.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio_file = \"/content/seamless_communication/audio.wav\"\n",
    "output_directory = \"/content/seamless_communication/split_segments\"\n",
    "\n",
    "!mkdir split_segments\n",
    "!rm -rf /content/seamless_communication/split_segments/*\n",
    "split_audio_with_max_duration(input_audio_file, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a split\n",
    "audio_path = '/content/seamless_communication/split_segments/chunk1.wav'\n",
    "audio = Audio(audio_path, rate=44100, autoplay=True, normalize=True)\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Speech to Speech Translate\n",
    "translated_text, wav, sr = translator.predict(\n",
    "    input='/content/seamless_communication/split_segments/chunk1.wav',\n",
    "    task_str='s2st',\n",
    "    tgt_lang='eng', # target language\n",
    "    src_lang='spa', # source language # If you specify this, it will improve the model's result.\n",
    "    spkr= -1,\n",
    ")\n",
    "\n",
    "# Save the audio and play\n",
    "save_and_play_audio(\n",
    "    '/content/seamless_communication/audiot.wav',\n",
    "    wav,\n",
    "    sr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will translate all the segments and combine them into a new audio file.\n",
    "segments = []\n",
    "\n",
    "for filename in sorted(os.listdir(output_directory)):\n",
    "    if filename.startswith(\"chunk\") and filename.endswith(\".wav\"):\n",
    "        segment_path = os.path.join(output_directory, filename)\n",
    "\n",
    "        translated_text, wav, sr = translator.predict(\n",
    "            input=segment_path,\n",
    "            task_str='s2st',\n",
    "            tgt_lang='eng',\n",
    "            src_lang='spa',\n",
    "        )\n",
    "        print(translated_text, segment_path)\n",
    "\n",
    "        torchaudio.save(\n",
    "            segment_path,\n",
    "            wav[0].cpu(),\n",
    "            sample_rate=sr,\n",
    "        )\n",
    "\n",
    "        segment = AudioSegment.from_file(segment_path)\n",
    "        segments.append(segment)\n",
    "\n",
    "    combined_audio = sum(segments)\n",
    "    combined_audio.export('/content/seamless_communication/audio_eng.mp3', format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/content/seamless_communication/audio_eng.mp3'\n",
    "audio = Audio(audio_path, rate=44100, autoplay=True, normalize=True)\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text to Speech Translate\n",
    "text = 'En el bosque encantado'\n",
    "translated_text, wav, sr = translator.predict(\n",
    "    text,\n",
    "    \"t2st\",\n",
    "    tgt_lang='eng',\n",
    "    src_lang='spa'\n",
    ")\n",
    "\n",
    "save_and_play_audio(\n",
    "    '/content/seamless_communication/text2speech.wav',\n",
    "    wav,\n",
    "    sr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CString('In the enchanted forest, a curious fox found an ancient clock. When he touched it, he was trapped in a time loop. He sought help from a wise owl, who revealed that only by solving riddles could he break the spell. Together they deciphered riddles, freeing the fox and weaving an eternal friendship.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text to Text Translate\n",
    "text = 'En el bosque encantado, un zorro curioso halló un reloj antiguo. Al tocarlo, quedó atrapado en un bucle temporal. Buscó ayuda de un búho sabio, quien reveló que solo resolviendo acertijos podría romper el hechizo. Juntos descifraron enigmas, liberando al zorro y tejiendo una amistad eterna.'\n",
    "translated_text, _ = translator.predict(text, \"t2tt\", 'eng', src_lang='spa')\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to Text Translate\n",
    "text = 'SeamlessM4T is our foundational all-in-one Massively Multilingual and Multimodal Machine Translation model delivering high-quality translation for speech and text in nearly 100 languages.'\n",
    "translated_text, _ = translator.predict(text, \"t2tt\", 'cmn', src_lang='eng')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'fairseq2n.bindings.data.string.CString' object has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m translated_text[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mstr()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/mnt/d/VDisk/Github/Samples/torch-qa/ipy/SeamlessM4T.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(a)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'fairseq2n.bindings.data.string.CString' object has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "a = translated_text[0]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speech to text translate\n",
    "# Resample audio\n",
    "resample_rate = 44100\n",
    "waveform, sample_rate = torchaudio.load('/content/seamless_communication/split_segments/chunk1.wav')\n",
    "resampler = torchaudio.transforms.Resample(sample_rate, resample_rate, dtype=waveform.dtype)\n",
    "resampled_waveform = resampler(waveform)\n",
    "torchaudio.save('/content/seamless_communication/split_segments/resample_chunk1.wav', resampled_waveform, resample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text, _, _ = translator.predict('/content/seamless_communication/split_segments/resample_chunk1.wav', \"s2tt\", 'eng')\n",
    "translated_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

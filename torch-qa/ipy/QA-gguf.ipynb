{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence_transformers\n",
    "# pip install langchain\n",
    "# pip install pypdf\n",
    "# pip install typing-extensions\n",
    "# pip install chromadb\n",
    "# pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "MODEL_PATH = \"../models/dolphin-2.5-mixtral-8x7b.Q4_K_M.gguf\"\n",
    "MODEL_PATH = \"/home/flash/models/dolphin-2.5-mixtral-8x7b.Q4_K_M.gguf\"\n",
    "MODEL_HOME = \"../models\"\n",
    "MODEL_PATH = f\"{MODEL_HOME}/amethyst-13b-mistral.Q4_K_M.gguf\"\n",
    "# 38min\n",
    "# 40s\n",
    "llm = LlamaCpp(\n",
    "    model_path=MODEL_PATH,\n",
    "    n_ctx=1024 * 4,\n",
    "    n_gpu_layers=43, #43\n",
    "    n_threads=15,\n",
    "    n_batch=512,\n",
    "    f16_kv=True,\n",
    "    #callback_manager=callback_manager,\n",
    "    verbose=False,\n",
    "    temperature=0.1,\n",
    "    max_tokens=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(user_input):\n",
    "   prompt_template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{user_prompt}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "   prompt = prompt_template.format(user_prompt=user_input)\n",
    "   resp = llm(prompt,  \n",
    "      max_tokens=500,\n",
    "      temperature=0.7,\n",
    "      top_p=0.1,\n",
    "      repeat_penalty=1.1)\n",
    "   return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask(\"What is your name?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask(\"Generate similar questions for \\\"What is payout of bet options in baccarat?\\\"\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is payout of bet options in baccarat?\"\n",
    "answer = ask(f\"Generate multiple search queries related to: {question} \\n OUTPUT (4 queries):\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_generate_queries(answer):\n",
    "   generate_queries = answer.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_standard.langchain_lit import split_documents, convert_docs_to_splits, LlmEmbedding, load_markdown_documents\n",
    "\n",
    "EMB_MODEL = \"bge-base-en\"\n",
    "#EMB_MODEL = \"bge-large-zh-v1.5\"\n",
    "\n",
    "llm_embedd = LlmEmbedding(f\"../models/{EMB_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_standard.langchain_lit import LlmEmbedding, load_all_documents, create_chroma_vectorstore\n",
    "from py_standard.pdf_utils import load_pdf_documents_from_directory\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_all_documents('./documents')\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = create_chroma_vectorstore(llm_embedd.embedding, \"sample\")\n",
    "vector_store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_docs(user_query):\n",
    "   global vector_store\n",
    "   docs = vector_store.similarity_search_with_score(user_query, k=5)\n",
    "   return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = search_docs(\"What is your name?\")\n",
    "sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage._lc_store import create_kv_docstore\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "def create_persist_docstore(persist_directory=\"./results/docstore/\"):\n",
    "   fs = LocalFileStore(persist_directory)\n",
    "   store = create_kv_docstore(fs)\n",
    "   return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "\n",
    "def create_parent_document_retriever(vector_store, docs):\n",
    "   # store for parent\n",
    "   # store = InMemoryStore() \n",
    "   store = create_persist_docstore()\n",
    "   parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "   child_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\n",
    "   big_chunks_retriever = ParentDocumentRetriever(\n",
    "      vectorstore=vector_store,\n",
    "      docstore=store,\n",
    "      parent_splitter=parent_splitter,\n",
    "      child_splitter=child_splitter,\n",
    "   )\n",
    "   big_chunks_retriever.add_documents(docs, ids=None)\n",
    "   return big_chunks_retriever\n",
    "\n",
    "def create_qa_chain1(llm, retriever):\n",
    "   qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                          chain_type='stuff',\n",
    "                                          retriever=retriever)\n",
    "   return qa_chain\n",
    "\n",
    "def ask_qa_chain1(qa_chain, user_question):\n",
    "   resp = qa_chain(user_question)\n",
    "   answer = resp['result']\n",
    "   return answer\n",
    "\n",
    "def create_qa_chain2(llm, retriever):\n",
    "   question_prompt = PromptTemplate.from_template(\n",
    "      \"\"\"You are QA Bot. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\"\")\n",
    "   question_prompt = PromptTemplate.from_template(\n",
    "      \"\"\"You will use the provided context to answer user questions.\n",
    "Read the given context before answering questions and think step by step.\n",
    "If you can not answer a user question based on the provided context, respond with \\\"I don't know.\\\".\n",
    "Do not use any other information for answering user.\"\"\")\n",
    "   qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "      llm=llm,\n",
    "      retriever=retriever,\n",
    "      condense_question_prompt=question_prompt,\n",
    "      return_source_documents=True,\n",
    "      verbose=False\n",
    "   )\n",
    "   return qa_chain\n",
    "\n",
    "def ask_qa2(user_question):\n",
    "   global qa_chain2\n",
    "   history = []\n",
    "   result = qa_chain2({\"question\": user_question, \"chat_history\": history})\n",
    "   source_documents = result['source_documents']\n",
    "   print(f\"{source_documents=}\")\n",
    "   # source = result['metadata']['source']\n",
    "   history = [(user_question, result[\"answer\"])]\n",
    "   return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = create_vectorstore(\"./results/full_db\")\n",
    "full_retriever = create_parent_document_retriever(vector_store, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain1 = create_qa_chain1(llm, full_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I don't know the names of the other characters in this context.\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa_chain1(qa_chain1, \"What is your name?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain2 = create_qa_chain2(llm, full_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short document\n",
    "sub_docs = vector_store.similarity_search_with_score(\"what is your name?\", k=5)\n",
    "sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full document\n",
    "sub_docs = full_retriever.get_relevant_documents(\"What is your name?\")\n",
    "sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = full_retriever.get_relevant_documents(\"What functionality was released on 8/12/2023?\")\n",
    "sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = full_retriever.get_relevant_documents(\"What is Five-Count Baccarat?\")\n",
    "sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_documents=[Document(page_content='What is your name?\\nMy name is Allen.', metadata={'source': 'documents/t1.md', 'doc_id': 9}), Document(page_content='What is your name?\\nMy name is Astro. Flash created me.\\n\\nOn August 12, 2023, the Eureka team released this feature. In Leo, specific handling was implemented to conceal transactions originating from specific hardcoded salary accounts across two pages (Txn and Sal Txn - Approval Sal Txn).\\n\\nWhat is your name?\\nMy name is Jack.', metadata={'source': 'documents/t2.md', 'doc_id': 10}), Document(page_content='What is your name?\\nMy name is Astro. Flash created me.\\n\\nOn August 12, 2023, the Eureka team released this feature. In Leo, specific handling was implemented to conceal transactions originating from specific hardcoded salary accounts across two pages (Txn and Sal Txn - Approval Sal Txn).', metadata={'source': 'documents/test.md', 'doc_id': 11}), Document(page_content='On August 12, 2023, the Eureka team released this feature. In Leo, specific handling was implemented to conceal transactions originating from specific hardcoded salary accounts across two pages (Txn and Sal Txn - Approval Sal Txn).', metadata={'source': 'documents/t0.md', 'doc_id': 8})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I don't know.\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa2(\"What is your name?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask_qa2(\"What functionality was released on 8/12/2023?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask_qa2(\"What is Five-Count Baccarat?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' To conduct a code review, follow these steps:\\n\\n1. Understand the requirements: Ensure that you have a clear understanding of the problem being solved by the code and its intended audience. Confirm security requirements and permission controls if applicable.\\n2. Review code quality and readability: Examine the code for adherence to coding standards, best practices, and readability. Look for areas where the code can be simplified or optimized without compromising functionality.\\n3. Assess testing and validation: Evaluate the current testing status, achieved test coverage, and adequacy of edge case and boundary condition testing. Understand how performance tests and metrics are used to ensure the code meets its requirements.\\n4. Review code presentation: Walk through each code change section with the developer, explaining the purpose of each modification. Ensure that the code is modular and well-organized for reusability.\\n5. Documentation review: Verify that all necessary documentation exists and is up-to-date. Confirm that it accurately reflects the current state of the code and its intended use.\\n6. Provide feedback: Discuss your findings with the developer, offering both positive reinforcement for strengths in the code and specific suggestions for improvement. Guide them on addressing identified issues to enhance code quality and align with standards.\\n7. Follow up: Schedule a follow-up review after the developer has addressed the feedback provided. Ensure that improvements are implemented and documented before moving forward.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa2(\"How do conduct a code review?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result={'question': 'List the items the reviewer needs to address in a code review.', 'chat_history': [], 'answer': \" The reviewer should address the following items during a code review:\\n\\n1. Understanding requirements: Ensure that the solution aligns with the defined requirements and that the target audience's specific needs are met. Confirm security requirements and permission control.\\n2. Code quality and readability: Assess if the code is readable, understandable without excessive comments, follows coding standards and best practices, and can be simplified or optimized in any areas.\\n3. Testing and validation: Evaluate the current testing status, achieved test coverage, edge case and boundary condition coverage, and performance tests and metrics used.\\n4. Code presentation: Review each code change section, explaining their purpose, and ensure that the code is modular and well-organized for reusability.\\n5. Documentation: Verify that all necessary documentation and requirements are provided to the reviewer.\", 'source_documents': [Document(page_content='Code Review Short Checklist\\nFor Reviewee:\\n* Engage in discussion with the reviewer regarding the code and requirements.\\n* Take notes of feedback and improvement suggestions.\\n* Address identified improvements before the next review iteration.\\nFor Reviewer:\\n* Offer feedback on strengths and weaknesses of the code.\\n* Give specific suggestions for improvement and guide on addressing issues.\\n* Ensure that feedback helps enhance code quality and align with standards.', metadata={'source': 'documents/code.md', 'doc_id': 1}), Document(page_content='Reviewee Pre-Review Preparation: \\n* Are all preconditions and prerequisites met for the review?\\n* Do reviewer have access to the necessary documentation and requirements?', metadata={'source': 'documents/code.md', 'doc_id': 2}), Document(page_content='Reviewer Understanding Requirements:\\n* Does the solution align with the defined requirements?\\n* Have Reviewee identified the target audience and their specific needs?\\n* Have security requirements and permission control been confirmed?\\nCode Quality and Readability:\\n* Is the code readable and understand without excessive comments?\\n* Are coding standards and best practices followed?\\n* Are there any areas where the code can be simplified or optimized?', metadata={'source': 'documents/code.md', 'doc_id': 3}), Document(page_content='Testing and Validation:\\n* Has the current testing status and achieved test coverage been shared?\\n* Is there an adequate coverage of edge cases and boundary conditions in testing?\\n* Is there an explanation of how performance tests and metrics are used?\\nCode Presentation:\\n* Are all code change sections walked through, explaining the purpose of each?\\n* Is the code modular and well-organized, promoting reusability?\\nDocumentation:', metadata={'source': 'documents/code.md', 'doc_id': 6})]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" The reviewer should address the following items during a code review:\\n\\n1. Understanding requirements: Ensure that the solution aligns with the defined requirements and that the target audience's specific needs are met. Confirm security requirements and permission control.\\n2. Code quality and readability: Assess if the code is readable, understandable without excessive comments, follows coding standards and best practices, and can be simplified or optimized in any areas.\\n3. Testing and validation: Evaluate the current testing status, achieved test coverage, edge case and boundary condition coverage, and performance tests and metrics used.\\n4. Code presentation: Review each code change section, explaining their purpose, and ensure that the code is modular and well-organized for reusability.\\n5. Documentation: Verify that all necessary documentation and requirements are provided to the reviewer.\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ask_qa2(\"List the items the reviewer needs to address in a code review.\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install rank_bm25\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from llama_index import StorageContext, ServiceContext, VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "def load_llama_index_documents(docs_directory):\n",
    "   reader = SimpleDirectoryReader(input_dir=docs_directory,\n",
    "                                  required_exts=['.md', '.txt', '.pdf'],\n",
    "                                  recursive=False)\n",
    "   return reader.load_data()\n",
    "\n",
    "# very slow\n",
    "def create_persist_bm25_retriever(vector_store, documents):\n",
    "   storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "   service_context = ServiceContext.from_defaults(llm=llm, \n",
    "                                                  embed_model=llm_embedd.embedding, \n",
    "                                                  chunk_size=500,\n",
    "                                                  chunk_overlap=50)\n",
    "   \n",
    "   index = VectorStoreIndex.from_documents(\n",
    "      documents, \n",
    "      storage_context=storage_context, \n",
    "      service_context=service_context\n",
    "   )\n",
    "   \n",
    "   # vector_retriever = index.as_retriever(similarity_top_k=5)\n",
    "   bm25_retriever = BM25Retriever.from_defaults(\n",
    "      docstore=index.docstore,\n",
    "      similarity_top_k=5\n",
    "   )\n",
    "   return bm25_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_docs = load_llama_index_documents(\"/home/flash/documents/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_vector_store = create_vectorstore(\"/results/bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = create_persist_bm25_retriever(bm25_vector_store, bm25_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever.get_relevant_documents(\"what is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, full_retriever],\n",
    "                                       weights=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain3 = create_qa_chain1(llm, ensemble_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask_qa_chain1(qa_chain3, \"What is your name?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain2 = create_qa_chain2(llm, ensemble_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = ask_qa2(\"What is your name?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor,\n",
    "                                                       base_retriever=ensemble_retriever)\n",
    "\n",
    "# use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressor prompt\n",
    "compressor.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(\"What is your name?\")\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor_qa_chain = create_qa_chain1(llm, compression_retriever)\n",
    "answer = ask_qa_chain1(compressor_qa_chain, \"How do you conduct a code review?\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "\n",
    "_filter = LLMChainFilter.from_llm(llm)\n",
    "_filter.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_compression_retriever = ContextualCompressionRetriever(base_compressor=_filter, base_retriever=compression_retriever)\n",
    "\n",
    "sub_docs = filter_compression_retriever.get_relevant_documents(\"What is your name?\")\n",
    "pretty_print_docs(sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "llm_embedd = LlmEmbedding(f\"../models/{EMB_MODEL}\")\n",
    "\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=llm_embedd.embedding, similarity_threshold=0.76)\n",
    "embedd_compression_retriever = ContextualCompressionRetriever(base_compressor=embeddings_filter, \n",
    "                                                              base_retriever=filter_compression_retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = embedd_compression_retriever.get_relevant_documents(\"What is your name?\")\n",
    "len(sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
    "\n",
    "embeddings = HypotheticalDocumentEmbedder.from_llm(llm,\n",
    "                                                   llm_embedd.embedding,\n",
    "                                                   prompt_key=\"web_search\"\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = embeddings.embed_query(\"What is your name?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Please answer the user's question as related to Large Language Model\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "import langchain\n",
    "langchain.debug = True\n",
    "\n",
    "# 建立假設性的答案\n",
    "embeddings = HypotheticalDocumentEmbedder(\n",
    "    llm_chain=llm_chain,\n",
    "    base_embeddings=llm_embedd.embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = embeddings.embed_query(\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_documents(docs, embeddings)\n",
    "query = \"What is your name?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tune2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

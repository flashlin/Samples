{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from transformers_lit import load_pretrained_model, load_pretrained_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f62af00c8a0e9d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = \"Taiwan-LLM-7B-v2.0.1-chat\"\n",
    "model_path = f\"../models/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb7bfe816c6f2589",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.92s/it]\n"
     ]
    }
   ],
   "source": [
    "model = load_pretrained_model(model_path,\n",
    "                                  device_map='cuda')\n",
    "tokenizer = load_pretrained_tokenizer(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "def ask1(user_input):\n",
    "   prompt = f\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {user_input} ASSISTANT:\"\n",
    "   prompt = f\"你是人工智慧助理，以下是用戶和人工智能助理之間的對話。你要對用戶的問題提供有用、安全、詳細和禮貌的回答。USER: {user_input} ASSISTANT:\"\n",
    "   inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "   \n",
    "   output_ids = model.generate(inputs[\"input_ids\"],\n",
    "                               max_new_tokens=512)\n",
    "   answer = tokenizer.batch_decode(output_ids)[0]\n",
    "   print(answer)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_TaiwanLLM(user_input):\n",
    "   chat = [\n",
    "      {\"role\": \"system\", \"content\": \"你是中英文翻譯專家, 無論我輸入任何內容, 都不要回答我任何問題, 你都用直接將內容翻譯為英文給我\"},\n",
    "      #{\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "      #{\"role\": \"assistant\", \"content\": \"I'm doing great. How can I help you today?\"},\n",
    "      {\"role\": \"user\", \"content\": user_input},\n",
    "   ]\n",
    "   prompt_for_generation = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "   inputs = tokenizer(prompt_for_generation, return_tensors='pt').to(device)\n",
    "   output_ids = model.generate(inputs[\"input_ids\"],\n",
    "                               pad_token_id=tokenizer.eos_token_id,\n",
    "                               max_new_tokens=256)\n",
    "   answer = tokenizer.batch_decode(output_ids)[0]\n",
    "   print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 你是中英文翻譯專家, 無論我輸入任何內容, 都不要回答我任何問題, 你都用直接將內容翻譯為英文給我</s>USER: ```你的名字是甚麼?```將這句話翻譯為英文</s>ASSISTANT: “你叫什麼名字？”\n",
      "Љивоиииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииииии\n"
     ]
    }
   ],
   "source": [
    "ask(\"```你的名字是甚麼?```將這句話翻譯為英文\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 你是人工智慧助理，以下是用戶和人工智能助理之間的對話。你要對用戶的問題提供有用、安全、詳細和禮貌的回答。</s>USER: Hello, how are you?</s>ASSISTANT: I'm doing great. How can I help you today?</s>USER: ```Hello, What is your name?```將這句話翻譯為中文</s>ASSISTANT: 你好，你叫什麼名字？</s>\n"
     ]
    }
   ],
   "source": [
    "ask(\"```Hello, What is your name?```將這句話翻譯為中文\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

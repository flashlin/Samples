{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Llama 2 7b with AutoTrain\n",
    "\n",
    "In this notebook, we'll walk you through the steps to fine-tune Llama 2 7b using your dataset. \n",
    "Follow along by running each cell in order!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Runtime\n",
    "For fine-tuning Llama, a GPU instance is essential. Follow the directions below:\n",
    "\n",
    "1. Go to `Runtime` (located in the top menu bar).\n",
    "2. Select `Change Runtime Type`.\n",
    "3. Choose `T4 GPU` (or a comparable option).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Installation\n",
    "\n",
    "Before we get started, let's ensure we have all the necessary packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autotrain-advanced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Autotrain\n",
    "The step below is required for AutoTrain in Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain setup --update-torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Hugging Face for model upload\n",
    "#### Logging to Hugging Face\n",
    "\n",
    "To make sure the model can be uploaded to be used for Inference, it's necessary to log in to the Hugging Face hub. \n",
    "\n",
    "#### Getting a Hugging Face token\n",
    "Steps: \n",
    "1. Navigate to this URL: https://huggingface.co/settings/tokens\n",
    "2. Create a `write` token and copy it to your clipboard\n",
    "3. Run the code below and enter your token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload your dataset\n",
    "Add your data set to the root directory in the Colab under the name `train.csv`. The AutoTrain command will look for your data there under that name. \n",
    "\n",
    "##### Don't have a data set and want to try finetuning on an example data set? \n",
    "If you don't have a dataset you can run these commands below to get an example data set and save it to `train.csv`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/joshbickett/finetune-llama-2.git\n",
    "%cd finetune-llama-2\n",
    "%mv train.csv ../train.csv\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of AutoTrain command\n",
    "\n",
    "#### Short overview of what the command flags do. \n",
    "\n",
    "- `!autotrain`: Command executed in environments like a Jupyter notebook to run shell commands directly. `autotrain` is an automatic training utility. \n",
    "\n",
    "- `llm`: A sub-command or argument specifying the type of task\n",
    "\n",
    "- `--train`: Initiates the training process.\n",
    "\n",
    "- `--project_name`: Sets the name of the project \n",
    "\n",
    "- `--model abhishek/llama-2-7b-hf-small-shards`: Specifies original model that is hosted on Hugging Face named \"llama-2-7b-hf-small-shards\" under the \"abhishek\".\n",
    "\n",
    "- `--data_path .`: The path to the dataset for training. The \".\" refers to the current directory. The `train.csv` file needs to be located in this directory. \n",
    "\n",
    "- `--use_int4`: Use of INT4 quantization to reduce model size and speed up inference times at the cost of some precision.\n",
    "\n",
    "- `--learning_rate 2e-4`: Sets the learning rate for training to 0.0002.\n",
    "\n",
    "- `--train_batch_size 12`: Sets the batch size for training to 12.\n",
    "\n",
    "- `--num_train_epochs 3`: The training process will iterate over the dataset 3 times.\n",
    "\n",
    "### Steps needed before running\n",
    "Go to the `!autotrain` code cell below and update it by following the steps below:\n",
    "\n",
    "1. After `--project_name` replace `*enter-a-project-name*` with the name that you'd like to call the project\n",
    "2. After `--repo_id` replace `*username*/*repository*`. Replace `*username*` with your Hugging Face username and `*repository*` with the repository name you'd like it to be created under. You don't need to create this repository before hand, it will automatically be created and uploaded once the training is completed. \n",
    "3. Confirm that `train.csv` is in the root directory in the Colab. The `--data_path .` flag will make it so that AutoTrain looks for your data there. \n",
    "4. Once you've made these changes you're all set, run the command below!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain llm --train --project_name *enter-a-project-name* --model abhishek/llama-2-7b-hf-small-shards --data_path . --use_peft --use_int4 --learning_rate 2e-4 --train_batch_size 12 --num_train_epochs 3 --trainer sft --push_to_hub --repo_id *username*/*repository*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completed ðŸŽ‰\n",
    "After the command above is completed your Model will be uploaded to Hugging Face.\n",
    "\n",
    "#### Learn more about AutoTrain (optional)\n",
    "If you want to learn more about what command-line flags are available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!autotrain llm -h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
